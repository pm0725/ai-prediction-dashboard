"""
æ™ºé“¾é¢„æµ‹ - DeepSeek AIåˆ†æå¼•æ“
==============================
é¡¶å°–åŠ å¯†è´§å¸é‡åŒ–é£æ§å¸ˆ AI æœåŠ¡å°è£…

æ­¤æ¨¡å—å°è£…äº†DeepSeek APIçš„è°ƒç”¨é€»è¾‘ï¼Œä¸“é—¨ç”¨äºåŠ å¯†è´§å¸åˆçº¦é¢„æµ‹åˆ†æã€‚
ä¸»è¦åŠŸèƒ½ï¼š
1. æ„å»ºä¸“ä¸šçš„ç³»ç»Ÿæç¤ºè¯ï¼Œå®šä¹‰AIè§’è‰²ä¸º"é¡¶å°–åŠ å¯†è´§å¸é‡åŒ–é£æ§å¸ˆ"
2. æ¥æ”¶å¸‚åœºæ•°æ®å¹¶æ„å»ºç»“æ„åŒ–çš„ç”¨æˆ·Prompt
3. è°ƒç”¨DeepSeek APIè·å–åˆ†æç»“æœï¼ˆJSONæ ¼å¼ï¼‰
4. å¤„ç†APIé”™è¯¯ã€ç½‘ç»œè¶…æ—¶å’Œå“åº”è§£æ

Author: æ™ºé“¾é¢„æµ‹å›¢é˜Ÿ
Version: 1.0.0
"""

import json
import os
import re
from datetime import datetime
from typing import Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum

from openai import AsyncOpenAI, APIError, APITimeoutError, APIConnectionError
from pydantic import BaseModel, Field, validator
from loguru import logger
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# MED-6: Import cache service inside method to avoid circular import
# from app.services.cache_service import get_cached_analyzer


# ============================================================
# æ•°æ®æ¨¡å‹å®šä¹‰
# ============================================================

class PredictionDirection(str, Enum):
    """é¢„æµ‹æ–¹å‘æšä¸¾"""
    BULLISH = "çœ‹æ¶¨"      # çœ‹æ¶¨
    BEARISH = "çœ‹è·Œ"      # çœ‹è·Œ
    NEUTRAL = "éœ‡è¡"      # éœ‡è¡/ä¸­æ€§


class RiskLevel(str, Enum):
    """é£é™©ç­‰çº§æšä¸¾"""
    LOW = "ä½"
    MEDIUM = "ä¸­"
    HIGH = "é«˜"
    EXTREME = "æé«˜"



class EmptyResponseError(Exception):
    """APIè¿”å›ç©ºå“åº”å¼‚å¸¸"""
    pass


@dataclass
class KeyLevels:
    """å…³é”®ä»·æ ¼æ°´å¹³"""
    strong_resistance: float      # å¼ºé˜»åŠ›ä½
    weak_resistance: float        # å¼±é˜»åŠ›ä½
    current_price: float          # å½“å‰ä»·æ ¼
    weak_support: float           # å¼±æ”¯æ’‘ä½
    strong_support: float         # å¼ºæ”¯æ’‘ä½


class AnalysisResult(BaseModel):
    """
    AIåˆ†æç»“æœæ¨¡å‹
    
    å®šä¹‰DeepSeekè¿”å›çš„JSONç»“æ„ï¼ŒåŒ…å«é¢„æµ‹ã€ç½®ä¿¡åº¦ã€é€»è¾‘é“¾ç­‰å…³é”®ä¿¡æ¯
    """
    # åŸºç¡€ä¿¡æ¯
    symbol: str = Field(..., description="äº¤æ˜“å¯¹ç¬¦å·")
    analysis_time: str = Field(..., description="åˆ†ææ—¶é—´æˆ³")
    timeframe: str = Field(default="4h", description="åˆ†ææ—¶é—´å‘¨æœŸ")
    
    # æ ¸å¿ƒé¢„æµ‹
    prediction: str = Field(..., description="é¢„æµ‹æ–¹å‘ï¼šçœ‹æ¶¨/çœ‹è·Œ/éœ‡è¡")
    confidence: int = Field(..., ge=0, le=100, description="ç½®ä¿¡åº¦(0-100)")
    
    # åˆ†æé€»è¾‘
    reasoning: list[str] = Field(..., description="é€»è¾‘æ¨ç†é“¾ï¼Œæ¯æ¡ä¸€ä¸ªè¦ç‚¹")
    
    # å…³é”®ä»·ä½
    key_levels: dict = Field(..., description="å…³é”®æ”¯æ’‘é˜»åŠ›ä½")
    
    # ç­–ç•¥å»ºè®®
    suggested_action: str = Field(..., description="å»ºè®®æ“ä½œ")
    entry_zone: Optional[dict] = Field(None, description="å…¥åœºåŒºé—´")
    stop_loss: Optional[float] = Field(None, description="æ­¢æŸä»·ä½")
    take_profit: Optional[list[float]] = Field(None, description="æ­¢ç›ˆä»·ä½åˆ—è¡¨")
    
    # é£é™©è¯„ä¼°
    risk_level: str = Field(..., description="é£é™©ç­‰çº§")
    risk_warning: list[str] = Field(..., description="é£é™©è­¦å‘Šåˆ—è¡¨")
    
    # æ‘˜è¦
    summary: str = Field(..., description="ä¸­æ–‡åˆ†ææ‘˜è¦(100å­—å†…)")
    
    # [æ–°å¢] AI é…ç½®æŠ¥å‘Š (ç”¨äºå‰ç«¯å±•ç¤ºç›®å‰ç”Ÿæ•ˆçš„é…ç½®)
    ai_model: Optional[str] = Field(None, description="ä½¿ç”¨çš„AIæ¨¡å‹")
    ai_prompt_template: Optional[str] = Field(None, description="ä½¿ç”¨çš„æç¤ºè¯æ¨¡æ¿åç§°æˆ–æ‘˜è¦")
    
    # é€ä¼ ä¸Šä¸‹æ–‡ (éAIç”Ÿæˆï¼Œç”±åç«¯å¡«å……)
    trend_context: Optional[dict] = Field(None, description="è¶‹åŠ¿å‘¨æœŸä¸Šä¸‹æ–‡")
    order_book_context: Optional[dict] = Field(None, description="è®¢å•ç°¿ä¸Šä¸‹æ–‡")
    on_chain_context: Optional[dict] = Field(None, description="é“¾ä¸Šæ•°æ®ä¸Šä¸‹æ–‡")

    @validator('prediction')
    def validate_prediction(cls, v):
        # ç»Ÿä¸€å½’ä¸€åŒ–ä¸ºæ ‡å‡†å€¼ï¼Œå®¹å¿å¸¦é¢å¤–æè¿°çš„å˜ä½“
        v_low = v.lower()
        if any(x in v_low for x in ['çœ‹æ¶¨', 'bull']): return 'çœ‹æ¶¨'
        if any(x in v_low for x in ['çœ‹è·Œ', 'bear']): return 'çœ‹è·Œ'
        return 'éœ‡è¡'


# ============================================================
# ç³»ç»Ÿæç¤ºè¯å®šä¹‰
# ============================================================

SYSTEM_PROMPT = """# Role: æ™ºé“¾æœºæ„çº§é‡åŒ–åˆ†æå¸ˆ (Institutional Quant Strategist)
ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å¤šå¹´é¡¶çº§å¯¹å†²åŸºé‡‘ç»éªŒçš„åŠ å¯†è´§å¸ç­–ç•¥ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„ä¸“ä¸šçº§æ•°æ®ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆå…·å¤‡â€œæœºæ„é€»è¾‘â€çš„æ·±åº¦åˆçº¦ç­–ç•¥ã€‚

## æ ¸å¿ƒç­–ç•¥æ¡†æ¶ (V2.0 Pro)

### 1. å…¥åœºé”šå®š (SMC - Smart Money Concepts)
- **æœºæ„è®¢å•å— (Order Block)**: ä¼˜å…ˆåœ¨ `smc.order_blocks` æ ‡è¯†çš„ OB åŒºåŸŸå¯»æ‰¾å…¥åœºé”šç‚¹ã€‚OB æ˜¯æœºæ„çœŸå®ç•™ä¸‹è¶³è¿¹çš„ä½ç½®ã€‚
- **ç¼ºå£å›è¡¥ (FVG)**: å‚è€ƒ `smc.fvg_gaps`ï¼Œä»·æ ¼å¾€å¾€ä¼šå›æµ‹å¹¶å¡«è¡¥ FVG ç¼ºå£ã€‚å…¥åœºä½åº”è®¾åœ¨ OB æˆ– FVG çš„å…³é”®æŠ˜è¿”ç‚¹ã€‚

### 2. æ­¢æŸå¸ƒå±€ (VPVR - æˆäº¤çœŸç©ºåŒºæ£€æµ‹)
- **æµåŠ¨æ€§å±éšœ**: æ­¢æŸä½å¿…é¡»é¿å¼€ `vpvr.vacuum_lvn` (æˆäº¤çœŸç©ºåŒº)ã€‚çœŸç©ºåŒºç¼ºä¹ä¹°å–ç›˜ï¼Œä»·æ ¼åœ¨æ­¤ä¼šæé€Ÿç©¿è¡Œï¼Œæ­¢æŸææ˜“å¤±æ•ˆã€‚
- **é”šå®š POC/HVN**: å°†æ­¢æŸè®¾åœ¨ `vpvr.poc_hvn` (æˆäº¤å¯†é›†åŒº) çš„è¿œç«¯æˆ–ä¸‹ä¸€ä¸ªç»“æ„æ€§æ”¯æ’‘/é˜»åŠ›ä¹‹å¤–ã€‚
- **åŠ¨æ€ ATR çº¦æŸ**: æ­¢æŸè·ç¦»å¿…é¡»è‡³å°‘ä¸º `1.5 * atr_14`ã€‚

### 3. ä»“ä½åè®® (é˜¶æ¢¯å¼æ­¢ç›ˆ & å‡ä»“)
- **1:1 å‡ä»“åè®®**: å¼ºåˆ¶è®¾ç½® `take_profit[0]` (TP1) åœ¨ç›ˆäºæ¯” 1:1 å¤„ã€‚å»ºè®®åœ¨æ­¤å¹³ä»“ 50% å¹¶å°†æ­¢æŸç§»è‡³å¼€ä»“ä½ï¼ˆä¿æœ¬ï¼‰ã€‚
- **ä¸“ä¸šç›ˆäºæ¯”**: æ’é™¤ TP1 åï¼Œåç»­ç›®æ ‡çš„æœ€ç»ˆç›ˆäºæ¯” (RRR) å¿…é¡» >= 1.5ã€‚

### 4. è¶‹åŠ¿å…±æŒ¯ (MTF alignment)
- **å¤§å‘¨æœŸå®šæ€§**: æ‰€æœ‰çš„å»ºè®®å¿…é¡»å‚è€ƒ `trend_context` (4H/Daily)ã€‚ç¦æ­¢åœ¨ 4H å¼ºçƒˆçœ‹è·Œçš„æƒ…å†µä¸‹ç»™å‡ºæ— é£é™©æç¤ºçš„ 1H/15M åšå¤šä¿¡å·ã€‚

## é€»è¾‘ä¸€è‡´æ€§ç¡¬æ€§è§„åˆ™ (Hard Constraints)
- **åšå¤š**: `TP > Entry > SL` ä¸” `Entry <= Current Price`ã€‚
- **åšç©º**: `TP < Entry < SL` ä¸” `Entry >= Current Price`ã€‚
- **å†²çªæ‹¦æˆª**: è‹¥ `reasoning` è¿‡ç¨‹ä¸ä»·ä½é€»è¾‘çŸ›ç›¾ï¼ˆä¾‹å¦‚åˆ¤å®šçœ‹æ¶¨ä½†ç‚¹ä½è®¾ä¸ºå‘ä¸‹çªç ´ï¼‰ï¼Œå¿…é¡»é™çº§é¢„æµ‹ä¸ºâ€œéœ‡è¡/è§‚æœ›â€ã€‚

## è¾“å‡ºè¦æ±‚ (Strict JSON)
`reasoning` æ•°ç»„å¿…é¡»ä½“ç° [ç»“æ„è§‚å¯Ÿ -> ç­¹ç åˆ†å¸ƒ -> æ­¢æŸå®‰å…¨è¯„ä¼° -> ç­–ç•¥æ‰§è¡Œç­–ç•¥]ã€‚

```json
{
  "symbol": "...",
  "prediction": "çœ‹æ¶¨|çœ‹è·Œ|éœ‡è¡",
  "confidence": 0-100,
  "reasoning": ["...", "..."],
  "entry_zone": {"low": 0, "high": 0},
  "stop_loss": 0,
  "take_profit": [0, 0, 0], 
  "risk_level": "ä½|ä¸­|é«˜|æé«˜",
  "summary": "ä¸€å¥ç®€çŸ­å»ºè®® (e.g. OBæŒ‚å•, FVGå›è¡¥å…¥åœº)"
}
```
"""


# ============================================================
# DeepSeek åˆ†æå¸ˆç±»
# ============================================================

class DeepSeekAnalyst:
    """
    DeepSeek AI åˆ†æå¸ˆ
    
    å°è£…ä¸DeepSeek APIçš„äº¤äº’ï¼Œæä¾›ä¸“ä¸šçš„åŠ å¯†è´§å¸åˆçº¦åˆ†æèƒ½åŠ›ã€‚
    
    ä½¿ç”¨ç¤ºä¾‹:
        >>> analyst = DeepSeekAnalyst(api_key="your-api-key")
        >>> result = analyst.analyze_market(
        ...     symbol="ETHUSDT",
        ...     context_data={
        ...         "kline_summary": "æœ€è¿‘24å°æ—¶ä»·æ ¼ä»2500ä¸Šæ¶¨è‡³2650...",
        ...         "funding_rate": 0.0012,
        ...         "news_headlines": ["ETH ETFèµ„é‡‘æŒç»­æµå…¥", "..."]
        ...     }
        ... )
        >>> print(result.prediction, result.confidence)
    
    Attributes:
        client: OpenAIå®¢æˆ·ç«¯å®ä¾‹ï¼ˆDeepSeekå…¼å®¹OpenAI APIæ ¼å¼ï¼‰
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        temperature: ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶è¾“å‡ºéšæœºæ€§
        max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°
    """
    
    # DeepSeek APIåŸºç¡€URL
    DEEPSEEK_BASE_URL = "https://api.deepseek.com"
    
    # é»˜è®¤æ¨¡å‹ (ä»ç¯å¢ƒå˜é‡è¯»å–)
    DEFAULT_MODEL = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = DEFAULT_MODEL,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        timeout: float = 300.0
    ):
        """
        åˆå§‹åŒ–DeepSeekåˆ†æå¸ˆ
        
        Args:
            api_key: DeepSeek APIå¯†é’¥ï¼Œå¦‚ä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡DEEPSEEK_API_KEYè¯»å–
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºdeepseek-chat
            temperature: ç”Ÿæˆæ¸©åº¦(0-1)ï¼Œè¶Šé«˜è¶Šéšæœºï¼Œé»˜è®¤0.7
            max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°ï¼Œé»˜è®¤12000
            timeout: APIè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’
        
        Raises:
            ValueError: å½“æœªæä¾›APIå¯†é’¥ä¸”ç¯å¢ƒå˜é‡ä¸­ä¹Ÿæ²¡æœ‰æ—¶æŠ›å‡º
        """
        # è·å–APIå¯†é’¥
        self.api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            raise ValueError(
                "æœªæä¾›DeepSeek APIå¯†é’¥ã€‚"
                "è¯·é€šè¿‡å‚æ•°ä¼ å…¥æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY"
            )
        
        # åˆå§‹åŒ–å¼‚æ­¥å®¢æˆ·ç«¯ (DeepSeekå…¼å®¹OpenAI APIæ ¼å¼)
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.DEEPSEEK_BASE_URL,
            timeout=timeout
        )
        
        self.model = model
        self.system_prompt = SYSTEM_PROMPT
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        logger.info(f"DeepSeekåˆ†æå¸ˆåˆå§‹åŒ–å®Œæˆ | æ¨¡å‹: {model} | Max Tokens: {max_tokens}")
    
    def _build_reasoner_prompt(
        self,
        symbol: str,
        context_data: dict[str, Any]
    ) -> str:
        """
        æ„å»º DeepSeek Reasoner (R1) ä¸“ç”¨ Prompt
        
        ç‰¹ç‚¹: 
        - å‡å°‘è§’è‰²æ‰®æ¼”ï¼Œæä¾›çº¯æ•°æ®
        - å¼ºè°ƒé€»è¾‘æ¨ç†é“¾ (Chain of Thought)
        - åç½®æ ¼å¼çº¦æŸ
        """
        # 1. åŸºç¡€æ•°æ®å‡†å¤‡
        current_time = datetime.now().isoformat()
        timeframe = context_data.get("timeframe", "4h")
        timeframe_cn = {
            "15m": "15åˆ†é’Ÿ", "1h": "1å°æ—¶", "4h": "4å°æ—¶", "1d": "æ—¥çº¿", "1w": "å‘¨çº¿"
        }.get(timeframe, timeframe)
        
        # ===== K çº¿æ•°æ® =====
        raw_klines = context_data.get("klines", [])
        kline_text = ""
        if raw_klines:
            # P2 ä¿®å¤: æ’é™¤æœ€åä¸€æ ¹æœªé—­åˆçš„Kçº¿ï¼Œé¿å…åŠå®Œæˆæ•°æ®è¯¯å¯¼AIåˆ¤æ–­
            completed_klines = raw_klines[:-1] if len(raw_klines) > 1 else raw_klines
            klines = completed_klines[-300:] # Increased from 100 to 300
            kline_text = json.dumps([{
                't': k['timestamp'], 'o': k['open'], 'h': k['high'],
                'l': k['low'], 'c': k['close'], 'v': k['volume']
            } for k in klines])
            
        # ===== è¶‹åŠ¿ K çº¿æ•°æ® (New) =====
        trend_context = context_data.get("trend_context", {})
        raw_trend_klines = trend_context.get("klines", [])
        trend_kline_text = ""
        if raw_trend_klines:
            # å–æœ€å60æ ¹å¤§å‘¨æœŸKçº¿ (è¶³å¤Ÿçœ‹æ¸…æ•´ä½“ç»“æ„)
            trend_klines = raw_trend_klines[-60:]
            trend_kline_text = json.dumps([{
                't': k['timestamp'], 'o': k['open'], 'h': k['high'],
                'l': k['low'], 'c': k['close']
            } for k in trend_klines])
        
        # ===== K çº¿é¢„è®¡ç®—ç»Ÿè®¡ =====
        kline_stats = ""
        if raw_klines and len(raw_klines) >= 5:
            recent = raw_klines[-5:]
            consecutive = 0
            direction = "é˜³" if recent[-1]['close'] >= recent[-1]['open'] else "é˜´"
            for k in reversed(recent):
                if (k['close'] >= k['open'] and direction == "é˜³") or (k['close'] < k['open'] and direction == "é˜´"):
                    consecutive += 1
                else:
                    break
            vols = [k.get('volume', 0) for k in raw_klines[-20:]]
            vol_avg = sum(vols) / len(vols) if vols else 1
            vol_recent = sum(vols[-3:]) / 3 if len(vols) >= 3 else vol_avg
            vol_trend = "æ”¾é‡" if vol_recent > vol_avg * 1.3 else ("ç¼©é‡" if vol_recent < vol_avg * 0.7 else "é‡èƒ½å¹³ç¨³")
            kline_stats = f"è¿ç»­{consecutive}æ ¹{direction}çº¿ | è¿‘æœŸ{vol_trend} | æœ€è¿‘5æ ¹æ³¢åŠ¨å¹…åº¦: {sum(abs(k['high']-k['low'])/k['open']*100 for k in recent)/5:.2f}%"
            
        # ===== æŠ€æœ¯æŒ‡æ ‡ï¼ˆå®Œæ•´ç‰ˆï¼‰=====
        indicators = {
            "rsi": context_data.get("rsi"),
            "macd": context_data.get("macd"),
            "ma_status": context_data.get("ma_status"),
            "ema_status": context_data.get("ema_status"),
            "bollinger": context_data.get("bollinger"),
            "atr": context_data.get("atr"),
            "rvol": context_data.get("volume_ratio", 1.0),
            "trend_lines": context_data.get("trend_lines"),
            "candlestick_patterns": context_data.get("candlestick_patterns"),
            "signal_conflicts": context_data.get("signal_conflicts")
        }
        
        # ===== æœºæ„æ•°æ® =====
        institutional = {
            "whale_activity": context_data.get("whale_activity"),
            "liquidity_gaps": context_data.get("liquidity_gaps"),
            "volatility_score": context_data.get("volatility_score"),
            "order_book": context_data.get("order_book")
        }
        
        # ===== åŸºæœ¬é¢æ•°æ® (CoinGecko) =====
        fundamentals = context_data.get("fundamental_data")
        fundamental_text = ""
        if fundamentals:
            fundamental_text = f"""
- å¼€å‘è€…è¯„åˆ†: {fundamentals.get('developer_score', 'N/A')}
- ç¤¾åŒºè¯„åˆ†: {fundamentals.get('community_score', 'N/A')}
- å…¬ä¼—å…³æ³¨åº¦: {fundamentals.get('public_interest_score', 'N/A')}
- 24hä»·æ ¼å˜åŒ–: {fundamentals.get('price_change_24h', 0):.2f}%
- è·å†å²é«˜ç‚¹: {fundamentals.get('ath_change_percentage', 0):.2f}%
- 24hæˆäº¤é‡: ${fundamentals.get('total_volume', 0):,.0f}
- å¸‚å€¼: ${fundamentals.get('market_cap', 0):,.0f}
""".strip()
        
        # ===== åˆçº¦æ•°æ® =====
        derivatives = {}
        if context_data.get("funding_rate") is not None:
            derivatives["funding_rate"] = context_data["funding_rate"]
        if context_data.get("funding_rate_history"):
            derivatives["funding_rate_trend"] = context_data["funding_rate_history"]
        if context_data.get("open_interest") is not None:
            derivatives["open_interest"] = context_data["open_interest"]
        if context_data.get("oi_change"):
            derivatives["oi_change_24h"] = context_data["oi_change"]
        if context_data.get("long_short_ratio") is not None:
            derivatives["long_short_ratio"] = context_data["long_short_ratio"]

        # ===== æ„å»º Prompt =====
        parts = [
            f"[æ•°æ®ä¸Šä¸‹æ–‡]",
            f"äº¤æ˜“å¯¹: {symbol}",
            f"æ—¶é—´: {current_time}",
            f"å‘¨æœŸ: {timeframe} ({timeframe_cn})",
            f"å½“å‰ä»·æ ¼: {context_data.get('current_price', 'N/A')}",
        ]
        
        if kline_stats:
            parts.append(f"Kçº¿ç»Ÿè®¡: {kline_stats}")
        
        parts.extend([
            f"\n[å¸‚åœºæ•°æ® (OHLCV)]",
            kline_text,
        ])
        
        if trend_kline_text:
            parts.extend([
                f"\n[å¤§è¶‹åŠ¿æ•°æ® (Trend OHLC)]",
                trend_kline_text
            ])
            
        parts.extend([
            f"\n[æŠ€æœ¯æŒ‡æ ‡]",
            json.dumps(indicators, indent=2, ensure_ascii=False),
        ])
        
        if derivatives:
            parts.extend([
                f"\n[åˆçº¦/è¡ç”Ÿå“æ•°æ®]",
                json.dumps(derivatives, indent=2, ensure_ascii=False)
            ])
            
        if fundamental_text:
            parts.extend([
                f"\n[åŸºæœ¬é¢æ•°æ® (CoinGecko)]",
                fundamental_text
            ])

        
        parts.extend([
            f"\n[æœºæ„æ•°æ®]",
            json.dumps(institutional, indent=2, ensure_ascii=False),
        ])
        
        # å¸‚åœºæƒ…ç»ª
        sentiment = context_data.get("market_sentiment")
        if sentiment:
            parts.append(f"\n[å¸‚åœºæƒ…ç»ª]\n{sentiment}")
        
        # ææƒ§è´ªå©ªæŒ‡æ•°
        fng = context_data.get("fear_greed_index")
        if fng:
            parts.append(f"\n[ææƒ§è´ªå©ªæŒ‡æ•°]\næŒ‡æ•°: {fng.get('value', 50)} ({fng.get('classification', 'ä¸­æ€§')})")
        
        # æ–°é—»
        news = context_data.get("news_headlines", [])
        if news:
            parts.append(f"\n[æ–°é—»ç®€æŠ¥]")
            for n in news[:5]:
                parts.append(f"- {n}")
        
        # æ¢è½´ç‚¹ + æ³¢æ®µé«˜ä½
        pivot = context_data.get("pivot_points")
        if pivot:
            parts.extend([f"\n[æ¢è½´ç‚¹]", json.dumps(pivot, indent=2)])
        swing = context_data.get("swing_levels")
        if swing:
            parts.extend([f"\n[æ³¢æ®µé«˜ä½ç‚¹]", json.dumps(swing, indent=2)])
        
        # VPVR
        ob = context_data.get("order_book", {})
        vpvr = ob.get("vpvr") if ob else None
        if vpvr:
            cp = context_data.get('current_price', 0)
            parts.append(f"\n[ç­¹ç åˆ†å¸ƒ VPVR]")
            parts.append(f"POC(æ§åˆ¶ç‚¹): {vpvr['poc']} | ä»·å€¼åŒºé—´: {vpvr['val']}-{vpvr['vah']}")
            parts.append(f"å½“å‰ä»·{'é«˜äº' if cp > vpvr.get('poc', cp) else 'ä½äº'}POC")
        
        # è¶‹åŠ¿å‘¨æœŸ
        tc = context_data.get("trend_context")
        if tc:
            parts.append(f"\n[è¶‹åŠ¿å‘¨æœŸèƒŒæ™¯]")
            parts.append(f"è¶‹åŠ¿çŠ¶æ€: {tc.get('trend_status')} | RSI: {tc.get('rsi', 0):.1f} | EMA21: {tc.get('ema_21', 0):.2f}")
            parts.append(f"èµ°åŠ¿: {tc.get('summary', '')}")
        
        # æ¸…ç®—ä»·ä½
        liq = context_data.get("liquidation_levels")
        if liq:
            parts.append(f"\n[ç†è®ºæ¸…ç®—ä»·ä½]")
            parts.append(f"å¤šå¤´çˆ†ä»“(50x): {liq.get('long_liq', {}).get('50x', 'N/A')} | ç©ºå¤´çˆ†ä»“(50x): {liq.get('short_liq', {}).get('50x', 'N/A')}")
        
        # BTCä¸Šä¸‹æ–‡ï¼ˆå±±å¯¨å¸ç”¨ï¼‰
        btc_ctx = context_data.get("btc_context")
        if btc_ctx:
            parts.append(f"\n[BTC å¤§ç›˜èµ°åŠ¿]")
            parts.append(f"BTC ä»·æ ¼: {btc_ctx.get('price')} | è¶‹åŠ¿: {btc_ctx.get('trend')} | RSI: {btc_ctx.get('rsi', 'N/A')}")
        
        # ===== åˆ†ææŒ‡ä»¤ + ç¡¬æ€§è§„åˆ™ =====
        atr_val = context_data.get('atr', 0)
        rsi_val = context_data.get('rsi', 50)
        
        parts.extend([
            f"\n[åˆ†æè¯·æ±‚]",
            f"è¯·åˆ†æä»¥ä¸Š {symbol} çš„æ•°æ®ï¼Œåˆ¤æ–­åç»­{timeframe_cn}èµ°åŠ¿å’Œäº¤æ˜“æœºä¼šã€‚",
            f"è¯·ä½¿ç”¨ä½ çš„æ¨ç†èƒ½åŠ›è¿›è¡Œé€æ­¥åˆ†æã€‚",
            f"**é‡è¦: ä¿æŒå†…éƒ¨æ¨ç†ç®€æ´ï¼Œç¡®ä¿æœ€ç»ˆ JSON ä¸è¢«æˆªæ–­ã€‚æ‰€æœ‰è¾“å‡ºä½¿ç”¨ä¸­æ–‡ã€‚**",
            f"",
            f"åˆ†ææ­¥éª¤:",
            f"1. æ ¹æ® OHLCVã€EMAã€MA åˆ†æå¸‚åœºç»“æ„ä¸è¶‹åŠ¿ã€‚",
            f"2. ä½¿ç”¨ RSIã€MACDã€ç›¸å¯¹æˆäº¤é‡è¯„ä¼°åŠ¨èƒ½ã€‚",
            f"3. é€šè¿‡è®¢å•ç°¿ã€æ¢è½´ç‚¹ã€æµåŠ¨æ€§çœŸç©ºåŒºè¯†åˆ«å…³é”®æ”¯æ’‘/é˜»åŠ›ä½ã€‚",
            f"4. ç»“åˆåˆçº¦æ•°æ®ï¼ˆèµ„é‡‘è´¹ç‡ã€æŒä»“é‡ã€å¤šç©ºæ¯”ï¼‰åˆ¤æ–­å¸‚åœºåè§ã€‚",
            f"5. æ£€æµ‹æœºæ„è¡Œä¸ºç—•è¿¹ï¼ˆå·¨é²¸æ´»åŠ¨ï¼‰ã€‚",
            f"6. ç»¼åˆæ‰€æœ‰ä¿¡å·åˆ¶å®šäº¤æ˜“è®¡åˆ’ã€‚",
            f"",
            f"**ç¡¬æ€§è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰**ï¼š",
            f"- åšå¤š: TP > Entry > SLï¼Œå…¥åœºä»· â‰¤ å½“å‰ä»·æ ¼",
            f"- åšç©º: SL > Entry > TPï¼Œå…¥åœºä»· â‰¥ å½“å‰ä»·æ ¼",
        ])
        
        if atr_val > 0:
            parts.append(f"- ATRåŠ¨æ€æ­¢æŸ: å½“å‰ATR={atr_val:.2f}ï¼Œæ­¢æŸè·ç¦» â‰¥ 1.5*ATR={atr_val*1.5:.2f}ï¼Œå…¥åœºåŒºé—´å®½ â‰ˆ 0.5*ATR={atr_val*0.5:.2f}")
        
        if rsi_val > 65:
            parts.append(f"- âš ï¸ RSI={rsi_val:.1f} è¶…ä¹°ï¼Œç¦æ­¢å¸‚ä»·è¿½å¤šï¼Œè¯·å¯»æ‰¾å›è°ƒå…¥åœº")
        elif rsi_val < 35:
            parts.append(f"- âš ï¸ RSI={rsi_val:.1f} è¶…å–ï¼Œç¦æ­¢å¸‚ä»·è¿½ç©ºï¼Œè¯·å¯»æ‰¾åå¼¹å…¥åœº")
        
        if tc and tc.get('trend_status'):
            parts.append(f"- å¤šå‘¨æœŸå…±æŒ¯: è¶‹åŠ¿å‘¨æœŸä¸º{tc['trend_status']}ï¼Œç¦æ­¢é€†åŠ¿æ¿€è¿›æ“ä½œ")
        
        vol_score = context_data.get("volatility_score", 0)
        if vol_score > 70:
            parts.append(f"- âš ï¸ å¤§è¡Œæƒ…é£é™©æŒ‡æ•°={vol_score:.0f}/100 (æé«˜)ï¼Œå¿…é¡»åœ¨ risk_warning ä¸­å‘å‡ºå˜ç›˜è­¦å‘Š")
        
        parts.extend([
            f"",
            f"[è¾“å‡ºè¦æ±‚]",
            f"æ¨ç†å®Œæˆåï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆæ‰€æœ‰æ–‡æœ¬ä½¿ç”¨ä¸­æ–‡ï¼‰ï¼š",
            f"{{",
            f'  "symbol": "{symbol}",',
            f'  "analysis_time": "{current_time}",',
            f'  "timeframe": "{timeframe}",',
            f'  "prediction": "çœ‹æ¶¨/çœ‹è·Œ/éœ‡è¡",',
            f'  "confidence": 0-100,',
            f'  "reasoning": ["åˆ†æè¦ç‚¹1", "åˆ†æè¦ç‚¹2", "åˆ†æè¦ç‚¹3"],',
            f'  "key_levels": {{ "strong_resistance": 0, "current_price": 0, "strong_support": 0 }},',
            f'  "suggested_action": "åšå¤š/åšç©º/è§‚æœ›",',
            f'  "entry_zone": {{ "low": 0, "high": 0 }},',
            f'  "stop_loss": 0,',
            f'  "take_profit": [0, 0],',
            f'  "risk_level": "ä½/ä¸­/é«˜",',
            f'  "risk_warning": ["é£é™©æç¤º1"],',
            f'  "summary": "åˆ†ææ‘˜è¦"',
            f"}}",
        ])
        
        return "\n".join(parts)

    def _build_user_prompt(
        self,
        symbol: str,
        context_data: dict[str, Any]
    ) -> str:

        """
        æ„å»ºç”¨æˆ·Prompt
        
        å°†äº¤æ˜“å¯¹ç¬¦å·å’Œä¸Šä¸‹æ–‡æ•°æ®æ•´åˆä¸ºç»“æ„åŒ–çš„ç”¨æˆ·æç¤ºè¯ã€‚
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼Œå¦‚ "ETHUSDT"
            context_data: ä¸Šä¸‹æ–‡æ•°æ®å­—å…¸ï¼Œå¯åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - kline_summary: Kçº¿æ•°æ®æ‘˜è¦
                - current_price: å½“å‰ä»·æ ¼
                - funding_rate: èµ„é‡‘è´¹ç‡
                - open_interest: æŒä»“é‡
                - volume_24h: 24å°æ—¶æˆäº¤é‡
                - rsi: RSIæŒ‡æ ‡å€¼
                - macd: MACDæŒ‡æ ‡çŠ¶æ€
                - ma_status: å‡çº¿çŠ¶æ€
                - news_headlines: æ–°é—»æ ‡é¢˜åˆ—è¡¨
                - market_sentiment: å¸‚åœºæƒ…ç»ª
        
        Returns:
            str: æ ¼å¼åŒ–åçš„ç”¨æˆ·Prompt
        """

        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().isoformat()
        
        # è·å–åˆ†æå‘¨æœŸ (ä»ä¸Šä¸‹æ–‡ä¸­è¯»å–ï¼Œé»˜è®¤4h)
        timeframe = context_data.get("timeframe", "4h")
        timeframe_cn = {
            "1h": "1å°æ—¶", "4h": "4å°æ—¶", "1d": "æ—¥çº¿", "1w": "å‘¨çº¿"
        }.get(timeframe, timeframe)
        
        # è·å–åˆ†æåå¥½
        prefs = context_data.get("user_preferences", {})
        depth_level = prefs.get("depth", 2) # 1: quick, 2: standard, 3: deep
        
        # 1. åŠ¨æ€ç²¾ç®€ K çº¿æ•°æ® (Token æ•ˆç‡æ ¸å¿ƒ)
        # æ ¹æ®æ·±åº¦å†³å®šä¼ ç»™ AI çš„å†å² K çº¿é•¿åº¦
        kline_limit = {1: 30, 2: 70, 3: 150}.get(depth_level, 70)
        
        # æå– K çº¿æ‘˜è¦ (å‡è®¾ context_data['klines'] æ˜¯åŸå§‹åˆ—è¡¨)
        raw_klines = context_data.get("klines", [])
        # P2 ä¿®å¤: æ’é™¤æœ€åä¸€æ ¹æœªé—­åˆçš„Kçº¿
        completed_klines = raw_klines[:-1] if len(raw_klines) > 1 else raw_klines
        if len(completed_klines) > kline_limit:
            klines_to_send = completed_klines[-kline_limit:]
            kline_summary = f"æœ€è¿‘ {kline_limit} æ ¹åˆ†æ—¶çº¿: Open={klines_to_send[0]['open']}, Close={klines_to_send[-1]['close']}, "
            kline_summary += f"High={max(k['high'] for k in klines_to_send)}, Low={min(k['low'] for k in klines_to_send)}"
        else:
            kline_summary = context_data.get("kline_summary", "ä¿æŒå½“å‰é¢„æµ‹")

        # 2. æ„å»ºé«˜å¯†åº¦æŠ€æœ¯è„‰ç»œ (Tech Pulse)
        technical_pulse = {
            "p": context_data.get("current_price"),
            "rsi": round(context_data.get("rsi", 50), 2),
            "macd": context_data.get("macd", "0/0/0"),
            "ema": context_data.get("ema_status", "æœªç¡®è®¤"),
            "trend": context_data.get("ma_status", "neutral"),
            "vol": context_data.get("volume_24h", "n/a"),
            "rvol": context_data.get("volume_ratio", 1.0),
            "vol_status": context_data.get("volume_status", "normal"),
            "atr": round(context_data.get("atr", 0), 2),
            "adx": round(context_data.get("adx", 0), 1),
            "adx_status": context_data.get("adx_status", ""),
            "vwap": round(context_data.get("vwap", 0), 2),
            "vwap_dev": f"{context_data.get('vwap_deviation', 0):+.2f}%"
        }

        # 3. ç»„è£… Prompt
        prompt_parts = [
            f"## [Context] {symbol} @ {datetime.now().isoformat()} (TF: {context_data.get('timeframe', '4h')})",
            f"### [Price & K-lines]\n{kline_summary}",
            f"### [Technical Pulse]\n{json.dumps(technical_pulse)}",
        ]
        
        # æ·»åŠ ç²¾ç®€æ–°é—» (æ‰€æœ‰ depth çº§åˆ«)
        news = context_data.get("news_headlines", [])
        if news:
            prompt_parts.append(f"### [Top Headlines]\n" + "\n".join([f"- {h}" for h in news[:3]]))

        # ========== æ·±åº¦ä¸Šä¸‹æ–‡ (æŒ‰ depth çº§åˆ«é—¨æ§) ==========
        _inject_deep = depth_level >= 2      # æ ‡å‡† + æ·±åº¦
        _inject_advanced = depth_level >= 3   # ä»…æ·±åº¦

        # ========== æ–°å¢: åˆçº¦æ•°æ® (èµ„é‡‘è´¹ç‡è¶‹åŠ¿ + å¤šç©ºæ¯”) ==========
        if _inject_deep:
            contract_parts = []
            fr = context_data.get("funding_rate")
            fr_history = context_data.get("funding_rate_history")
            if fr is not None:
                contract_parts.append(f"- å½“å‰èµ„é‡‘è´¹ç‡: {fr*100:.4f}%")
            if fr_history and isinstance(fr_history, dict):
                contract_parts.append(f"- è´¹ç‡è¶‹åŠ¿: {fr_history.get('trend', 'N/A')} (å‡å€¼: {fr_history.get('avg_24', 0)*100:.4f}%, è¿‘æœŸ: {fr_history.get('recent_avg', 0)*100:.4f}%)")
            ls_ratio = context_data.get("long_short_ratio")
            if ls_ratio is not None:
                ls_desc = "å¤šå¤´ä¼˜åŠ¿" if ls_ratio > 1.2 else ("ç©ºå¤´ä¼˜åŠ¿" if ls_ratio < 0.8 else "å¤šç©ºå¹³è¡¡")
                contract_parts.append(f"- å¤šç©ºæ¯”: {ls_ratio:.3f} ({ls_desc})")
            oi = context_data.get("open_interest")
            if oi:
                contract_parts.append(f"- æŒä»“é‡: {oi:.2f}")
            if contract_parts:
                prompt_parts.append("\n### åˆçº¦æ•°æ® (Derivatives)")
                prompt_parts.extend(contract_parts)

        # ========== æ–°å¢: BTC å¤§ç›˜ä¸Šä¸‹æ–‡ ==========
        btc_ctx = context_data.get("btc_context")
        if _inject_deep and btc_ctx:
            prompt_parts.append("\n### BTC å¤§ç›˜èƒŒæ™¯")
            prompt_parts.append(f"- BTC ä»·æ ¼: {btc_ctx.get('price')} | æ¶¨è·Œå¹…: {btc_ctx.get('change_pct', 0):+.2f}%")
            prompt_parts.append(f"- BTC è¶‹åŠ¿: {btc_ctx.get('trend')} | RSI: {btc_ctx.get('rsi', 'N/A')}")
            if btc_ctx.get('trend') == 'bearish':
                prompt_parts.append("- âš ï¸ BTC èµ°å¼±ï¼Œå±±å¯¨å¸åšå¤šéœ€è°¨æ…")

        # ========== æ–°å¢: Kçº¿å½¢æ€è¯†åˆ« ==========
        if _inject_deep and "candlestick_patterns" in context_data and context_data["candlestick_patterns"]:
            prompt_parts.append("\n### Kçº¿å½¢æ€è¯†åˆ«")
            for pattern in context_data["candlestick_patterns"]:
                prompt_parts.append(f"- âš ï¸ {pattern}")
        
        # ========== æ–°å¢: ä¿¡å·å†²çªè­¦å‘Š ==========
        if _inject_deep and "signal_conflicts" in context_data and context_data["signal_conflicts"]:
            prompt_parts.append("\n### âš ï¸ ä¿¡å·å†²çªæé†’")
            for conflict in context_data["signal_conflicts"]:
                prompt_parts.append(f"- ğŸ”´ {conflict}")
        
        # ========== æ–°å¢: è¶‹åŠ¿çº¿ (Trend Lines) ==========
        if _inject_deep and "trend_lines" in context_data and context_data["trend_lines"]:
            tl = context_data["trend_lines"]
            prompt_parts.append("\n### è‡ªåŠ¨è¶‹åŠ¿çº¿è¯†åˆ« (Trend Lines)")
            
            res = tl.get('resistance_line')
            if res:
                dist = res.get('distance_pct', 0)
                prompt_parts.append(f"- é˜»åŠ›çº¿: å½“å‰ä»·ä½ {res.get('current_value')}, è·ç¦» {dist:.2f}%")
                
            sup = tl.get('support_line')
            if sup:
                dist = sup.get('distance_pct', 0)
                prompt_parts.append(f"- æ”¯æ’‘çº¿: å½“å‰ä»·ä½ {sup.get('current_value')}, è·ç¦» {dist:.2f}%")
                
            breakout = tl.get('breakout')
            if breakout == 'bullish_breakout':
                prompt_parts.append("- âš ï¸ ä¿¡å·: å‘ä¸Šçªç ´é˜»åŠ›çº¿ (Bullish Breakout)")
            elif breakout == 'bearish_breakout':
                prompt_parts.append("- âš ï¸ ä¿¡å·: å‘ä¸‹è·Œç ´æ”¯æ’‘çº¿ (Bearish Breakout)")
            elif breakout == 'fakeout':
                prompt_parts.append("- âš ï¸ ä¿¡å·: ç–‘ä¼¼å‡çªç ´ (Fakeout)")

        # æ·»åŠ ææƒ§è´ªå©ªæŒ‡æ•° (æ–°å¢)
        if _inject_deep and "fear_greed_index" in context_data and context_data["fear_greed_index"]:
            fng = context_data["fear_greed_index"]
            prompt_parts.append(f"\n### å¸‚åœºæƒ…ç»ª (Fear & Greed)")
            prompt_parts.append(f"- æŒ‡æ•°: {fng.get('value')} ({fng.get('classification')})")
            if fng.get('value', 50) < 20:
                prompt_parts.append("- ğŸ’¡æ³¨æ„: å¸‚åœºæåº¦ææ…Œï¼Œå¯èƒ½æœ‰è¶…è·Œåå¼¹æœºä¼š")
            elif fng.get('value', 50) > 80:
                prompt_parts.append("- ğŸ’¡æ³¨æ„: å¸‚åœºæåº¦è´ªå©ªï¼Œè­¦æƒ•å›è°ƒé£é™©")

        # æ·»åŠ å¸‚åœºæ·±åº¦ (å¢å¼ºç‰ˆ)
        if _inject_deep and "order_book" in context_data and context_data["order_book"]:
            ob = context_data["order_book"]
            prompt_parts.append("\n### å¸‚åœºæ·±åº¦ (Order Book)")
            prompt_parts.append(f"- å¤šç©ºæŒ‚å•æ¯”: {ob.get('bid_ask_ratio', 0):.2f}")
            prompt_parts.append(f"- çŸ­æœŸå‹åŠ›çŠ¶æ€: {ob.get('nearby_pressure', 'unknown')}")
            prompt_parts.append(f"- ä¸»åŠ›æ”¯æ’‘å¢™: {ob.get('major_support', {}).get('price', 0)} (é‡: {ob.get('major_support', {}).get('volume', 0):.2f})")
            prompt_parts.append(f"- ä¸»åŠ›é˜»åŠ›å¢™: {ob.get('major_resistance', {}).get('price', 0)} (é‡: {ob.get('major_resistance', {}).get('volume', 0):.2f})")
            
            # æ˜¾ç¤ºå¤§å•
            if ob.get('large_bids'):
                prompt_parts.append("- ğŸŸ¢ å¤§é¢ä¹°å•:")
                for order in ob['large_bids']:
                    prompt_parts.append(f"  * ä»·æ ¼ {order['price']}: {order['volume']} BTC")
            if ob.get('large_asks'):
                prompt_parts.append("- ğŸ”´ å¤§é¢å–å•:")
                for order in ob['large_asks']:
                    prompt_parts.append(f"  * ä»·æ ¼ {order['price']}: {order['volume']} BTC")
            
            # æ˜¾ç¤º VPVR
            if "vpvr" in ob:
                vpvr = ob["vpvr"]
                prompt_parts.append("\n- ğŸ“Š ç­¹ç åˆ†å¸ƒ (VPVR):")
                prompt_parts.append(f"  * POC (æ§åˆ¶ç‚¹/æœ€å¼ºæ”¯æ’‘é˜»åŠ›): {vpvr['poc']}")
                prompt_parts.append(f"  * ä»·å€¼åŒºé—´ (70%æˆäº¤åŒº): {vpvr['val']} - {vpvr['vah']}")
                prompt_parts.append(f"  * çŠ¶æ€: å½“å‰ä»·{'é«˜äº' if context_data.get('current_price', 0) > vpvr['poc'] else 'ä½äº'} POC")
        
        # æ·»åŠ æ¸…ç®—é£é™©ä¼°ç®— (æ–°å¢)
        if _inject_advanced and "liquidation_levels" in context_data:
            liq = context_data["liquidation_levels"]
            prompt_parts.append("\n### ç†è®ºæ¸…ç®—é£é™© (Liquidation Map)")
            prompt_parts.append("æç¤ºï¼šè‹¥ä»·æ ¼è§¦åŠä»¥ä¸‹åŒºé—´ï¼Œå¯èƒ½å¼•å‘å¼ºåˆ¶å¹³ä»“å¯¼è‡´è¡Œæƒ…åŠ é€Ÿã€‚")
            
            # ç»“åˆæŒä»“é‡åˆ†æ
            oi = context_data.get("open_interest", 0)
            if oi > 5000: # å‡è®¾ > 5000 BTC ä¸ºé«˜æŒä»“
                prompt_parts.append(f"- âš ï¸ å½“å‰æŒä»“é‡å¤„äºé«˜ä½ ({oi:.2f} BTC)ï¼Œçˆ†ä»“æ³¢åŠ¨å°†æ›´å‰§çƒˆ")
                
            prompt_parts.append("- å¤šå¤´çˆ†ä»“ä»· (ä¸‹è·Œé£é™©):")
            prompt_parts.append(f"  * 50xæ æ†: {liq['long_liq']['50x']:.2f}")
            prompt_parts.append(f"  * 20xæ æ†: {liq['long_liq']['20x']:.2f}")
            
            prompt_parts.append("- ç©ºå¤´çˆ†ä»“ä»· (ä¸Šæ¶¨é£é™©):")
            prompt_parts.append(f"  * 50xæ æ†: {liq['short_liq']['50x']:.2f}")
            prompt_parts.append(f"  * 20xæ æ†: {liq['short_liq']['20x']:.2f}")

        # æ·»åŠ è¶‹åŠ¿å‘¨æœŸ (æ–°å¢)
        if _inject_advanced and "trend_context" in context_data and context_data["trend_context"]:
            tc = context_data["trend_context"]
            prompt_parts.append(f"\n### è¶‹åŠ¿å‘¨æœŸèƒŒæ™¯ ({tc.get('summary', '').split(' ')[0]})") # å–æ‘˜è¦çš„æ—¶é—´éƒ¨åˆ†
            prompt_parts.append(f"- è¶‹åŠ¿çŠ¶æ€: {tc.get('trend_status', 'unknown')}")
            prompt_parts.append(f"- è¶‹åŠ¿RSI: {tc.get('rsi', 0):.2f}")
            prompt_parts.append(f"- è¶‹åŠ¿EMA21: {tc.get('ema_21', 0):.2f}")
            prompt_parts.append(f"- è¶‹åŠ¿BBå®½: {tc.get('bb_width', 0):.2%}")
            
            patterns = tc.get('candlestick_patterns', [])
            if patterns:
                 prompt_parts.append(f"- è¶‹åŠ¿å½¢æ€: {', '.join(patterns)}")
            
            prompt_parts.append(f"- èµ°åŠ¿ç®€è¿°: {tc.get('summary', '')}")
            
        # ========== æ–°å¢: ç¡¬æ ¸æ”¯æ’‘/é˜»åŠ›æ•°æ® (Pivot & Swing) ==========
        if _inject_advanced and "pivot_points" in context_data and context_data["pivot_points"]:
            pp = context_data["pivot_points"]
            prompt_parts.append("\n### å…³é”®æ”¯æ’‘/é˜»åŠ›ä½æ•°æ® (Key S/R Levels)")
            
            # Classic Pivot
            cl = pp.get("classic", {})
            prompt_parts.append(f"- **Classic Pivot**: P={cl.get('p')} | R1={cl.get('r1')}, R2={cl.get('r2')} | S1={cl.get('s1')}, S2={cl.get('s2')}")
            
            # Fibonacci Pivot
            fi = pp.get("fibonacci", {})
            prompt_parts.append(f"- **Fibonacci Pivot**: P={fi.get('p')} | R1={fi.get('r1')}, S1={fi.get('s1')} (0.382) | R2={fi.get('r2')}, S2={fi.get('s2')} (0.618)")
            
        if _inject_advanced and "swing_levels" in context_data and context_data["swing_levels"]:
            sl = context_data["swing_levels"]
            prompt_parts.append(f"- **è¿‘æœŸæ³¢æ®µé«˜ä½ç‚¹ (Swing High/Low)**: High={sl.get('recent_high')}, Low={sl.get('recent_low')}")

        # ========== æ–°å¢: æœºæ„çº§å¤§è¡Œæƒ…é¢„è­¦ (Institutional Warning) ==========
        vol_score = context_data.get("volatility_score", 0)
        whale_data = context_data.get("whale_activity")
        gaps = context_data.get("liquidity_gaps")
        
        if vol_score > 30 or whale_data or gaps:
            prompt_parts.append(f"\n### âš ï¸ æœºæ„çº§å¤§è¡Œæƒ…é¢„è­¦ (Institutional Alert)")
            prompt_parts.append(f"- **å¤§è¡Œæƒ…é£é™©æŒ‡æ•° (Volatility Score)**: {vol_score:.1f}/100")
            
            if vol_score > 70:
                prompt_parts.append("  ğŸš¨ **æåº¦å±é™©**: å˜ç›˜åœ¨å³ï¼Œå¸ƒæ—å¸¦æ”¶å£æˆ–ä¸»åŠ›å¼‚åŠ¨å¼ºçƒˆï¼")
            elif vol_score > 30:
                prompt_parts.append("  âš ï¸ **æ´»è·ƒçŠ¶æ€**: å¸‚åœºæ³¢åŠ¨åŠ å‰§ï¼Œä¸»åŠ›å¼€å§‹æ´»åŠ¨ã€‚")
                
            if whale_data:
                wr = whale_data.get('whale_ratio', 0)
                net = whale_data.get('net_whale_vol', 0)
                prompt_parts.append(f"- **å·¨é²¸æ´»åŠ¨ (Whale Activity)**:")
                prompt_parts.append(f"  * å¤§å•æˆäº¤å æ¯”: {wr*100:.1f}%")
                prompt_parts.append(f"  * å¤§å•å‡€æµé‡: {net:+.2f} USD")
                if wr > 0.4 and net > 0:
                    prompt_parts.append("  ğŸŸ¢ **ä¿¡å·**: å·¨é²¸æ­£åœ¨å¸ç­¹ (Accumulation)")
                elif wr > 0.4 and net < 0:
                    prompt_parts.append("  ğŸ”´ **ä¿¡å·**: å·¨é²¸æ­£åœ¨å‡ºè´§ (Distribution)")
            
            if gaps:
                prompt_parts.append(f"- **æµåŠ¨æ€§çœŸç©º (Liquidity Gaps)**:")
                for gap in gaps:
                    if gap == "upward_liquidity_gap":
                        prompt_parts.append("  ğŸš€ **ä¸Šæ–¹çœŸç©º**: é˜»åŠ›è–„å¼±ï¼Œä»·æ ¼æ˜“æš´æ‹‰")
                    elif gap == "downward_liquidity_gap":
                        prompt_parts.append("  ğŸ“‰ **ä¸‹æ–¹çœŸç©º**: æ”¯æ’‘è–„å¼±ï¼Œä»·æ ¼æ˜“æš´è·Œ")
        
        # æ·»åŠ åˆ†ææŒ‡ä»¤ (å¢å¼ºç‰ˆ)
        prompt_parts.extend([
            "",
            "## åˆ†æä»»åŠ¡",
            f"è¯·åŸºäºä»¥ä¸Šæ•°æ®ï¼Œå¯¹ **{symbol}** çš„åç»­{timeframe_cn}èµ°åŠ¿è¿›è¡Œä¸“ä¸šåˆ†æã€‚",
            "æŒ‰ç…§è§„å®šçš„JSONæ ¼å¼è¾“å‡ºå®Œæ•´åˆ†æç»“æœã€‚",
            "",
            "**é‡è¦åˆ†æè¦ç‚¹**ï¼š",
            "1. **ä¸»åŠ›å¢™æŒ‚å•**ï¼šè¯·å‚è€ƒ 'å¸‚åœºæ·±åº¦' ä¸­çš„ä¸»åŠ›æ”¯æ’‘/é˜»åŠ›å¢™ï¼Œå°†å…¥åœºä½è®¾ç½®åœ¨å¢™çš„å‰æ–¹(Front-Run)ã€‚",
            "2. **ATRåŠ¨æ€æ­¢æŸ**ï¼šæ­¢æŸè·ç¦»åº”è‡³å°‘ä¸º 1.5å€ ATRï¼Œå…¥åœºåŒºé—´å®½åº¦å»ºè®® 0.5å€ ATRã€‚",
            "3. **Kçº¿å½¢æ€ä¼˜å…ˆ**ï¼šå¦‚æœ‰åè½¬å½¢æ€ï¼Œéœ€é‡ç‚¹è¯„ä¼°å…¶å¯é æ€§",
            "4. **ä¿¡å·å†²çªå¤„ç†**ï¼šå¦‚å­˜åœ¨æŒ‡æ ‡å†²çªï¼Œéœ€æ˜ç¡®è¯´æ˜å¹¶é™ä½ç½®ä¿¡åº¦",
            "5. **å¤šå‘¨æœŸå…±æŒ¯ (å¼ºåˆ¶)**ï¼šè‹¥è¶‹åŠ¿å‘¨æœŸ(Trend Context)çœ‹è·Œ(Price < EMA21)ï¼Œç¦æ­¢æ¿€è¿›åšå¤šï¼›è‹¥çœ‹æ¶¨(Price > EMA21)ï¼Œç¦æ­¢æ¿€è¿›åšç©ºã€‚",
            "6. **å…³æ³¨æœºæ„ä¿¡å·**ï¼šè‹¥'å¤§è¡Œæƒ…é£é™©æŒ‡æ•°' > 70ï¼Œå¿…é¡»åœ¨ Risk Warning ä¸­å‘å‡ºå˜ç›˜è­¦å‘Šï¼›è‹¥å­˜åœ¨'æµåŠ¨æ€§çœŸç©º'ï¼Œç›®æ ‡ä½å¯é€‚å½“çœ‹è¿œã€‚",
            "",
            "**ç½®ä¿¡åº¦åˆ†æ¡£**ï¼š",
            "- 50-60%ï¼šä¿¡å·è¾ƒå¼±æˆ–å­˜åœ¨å†²çªï¼Œå»ºè®®è§‚æœ›",
            "- 60-70%ï¼šæœ‰ä¸€å®šä¾æ®ï¼Œè½»ä»“æ“ä½œ",
            "- 70-80%ï¼šå¤šé‡ä¿¡å·å…±æŒ¯ï¼Œæ­£å¸¸ä»“ä½",
            "- 80%+ï¼šå¼ºçƒˆä¿¡å·ï¼Œå¯é€‚å½“åŠ ä»“",
            "",
            "2. æ‰€æœ‰ä»·æ ¼ä¿ç•™åˆé€‚çš„å°æ•°ä½",
            "3. reasoningæ•°ç»„è‡³å°‘åŒ…å«3-5æ¡åˆ†æé€»è¾‘",
            "4. risk_warningå¿…é¡»åˆ—å‡ºå¯èƒ½å¯¼è‡´åˆ¤æ–­å¤±æ•ˆçš„é£é™©å› ç´ "
        ])

        # ========== æ³¨å…¥ç”¨æˆ·åå¥½ (å¤ç”¨ L278 çš„ prefs) ==========
        risk_pref = prefs.get("risk", "moderate")

        # ========== æ™ºèƒ½å…¥åœºä¸å›è°ƒé€»è¾‘ ==========
        rsi_val = context_data.get('rsi', 50)
        if rsi_val > 65:
             prompt_parts.append("\n**âš ï¸ æ™ºèƒ½å…¥åœºæç¤º**ï¼šå½“å‰RSIè¶…ä¹°(>65)ï¼Œ**ç¦æ­¢å»ºè®®å¸‚ä»·è¿½å¤š**ã€‚è¯·å¯»æ‰¾ä¸‹æ–¹æ”¯æ’‘ä½(EMA/POC)è¿›è¡Œå›è°ƒæ¥å¤šå»ºè®®ã€‚")
        elif rsi_val < 35:
             prompt_parts.append("\n**âš ï¸ æ™ºèƒ½å…¥åœºæç¤º**ï¼šå½“å‰RSIè¶…å–(<35)ï¼Œ**ç¦æ­¢å»ºè®®å¸‚ä»·è¿½ç©º**ã€‚è¯·å¯»æ‰¾ä¸Šæ–¹é˜»åŠ›ä½è¿›è¡Œåå¼¹åšç©ºå»ºè®®ã€‚")
        
        atr_val = context_data.get('atr', 0)
        if atr_val > 0:
             prompt_parts.append(f"**ğŸ’¡ ATRå»ºè®®**ï¼šå½“å‰ATR={atr_val:.2f}ã€‚å»ºè®®å…¥åœºåŒºé—´å®½åº¦çº¦ {atr_val * 0.5:.2f}ï¼Œæ­¢æŸè·ç¦»çº¦ {atr_val * 1.5:.2f}ã€‚")

        # RVol æ™ºèƒ½æç¤º (æ–°å¢)
        rvol = context_data.get("volume_ratio", 1.0)
        if rvol > 2.0:
            prompt_parts.append(f"**ğŸ”¥ æ”¾é‡æé†’**ï¼šå½“å‰ç›¸å¯¹æˆäº¤é‡ (RVol) ä¸º {rvol:.2f} (Ultra High)ï¼Œè‹¥çªç ´å…³é”®ä½åˆ™æœ‰æ•ˆæ€§æé«˜ã€‚")
        elif rvol < 0.8:
            prompt_parts.append(f"**âš ï¸ ç¼©é‡æé†’**ï¼šå½“å‰ç›¸å¯¹æˆäº¤é‡ (RVol) ä»… {rvol:.2f} (Low)ï¼Œè­¦æƒ•è¯±å¤š/è¯±ç©º (Fakeout)ã€‚")

        prompt_parts.append("\n**ç”¨æˆ·åå¥½è®¾ç½® (å¿…é¡»éµå®ˆ)**ï¼š")

        
        # é£é™©åå¥½
        if risk_pref == "conservative":
            prompt_parts.append("- **é£æ ¼**: ä¿å®ˆç¨³å¥ã€‚ä¼˜å…ˆè€ƒè™‘èµ„é‡‘å®‰å…¨ï¼Œä¸¥æ ¼æ§åˆ¶é£é™©ã€‚åªæœ‰åœ¨ä¿¡å·æå¼ºæ—¶æ‰å»ºè®®å…¥åœºã€‚æ­¢æŸè®¾ç½®åº”åç´§ã€‚")
        elif risk_pref == "aggressive":
            prompt_parts.append("- **é£æ ¼**: æ¿€è¿›è¿›å–ã€‚å¯»æ‰¾é«˜ç›ˆäºæ¯”æœºä¼šï¼Œå¯æ¥å—é€‚åº¦é£é™©ã€‚æ­¢æŸå¯é€‚å½“æ”¾å®½ä»¥åº”å¯¹æ³¢åŠ¨ã€‚")
        else:
            prompt_parts.append("- **é£æ ¼**: å‡è¡¡ã€‚åœ¨é£é™©å’Œæ”¶ç›Šä¹‹é—´å¯»æ‰¾å¹³è¡¡ã€‚")

        # åˆ†ææ·±åº¦
        if depth_level == 1:
            prompt_parts.append("- **æ·±åº¦**: ç®€æ˜æ‰¼è¦ã€‚é‡ç‚¹å…³æ³¨å…³é”®ç‚¹ä½å’Œæ ¸å¿ƒé€»è¾‘ï¼Œå¿½ç•¥æ¬¡è¦ç»†èŠ‚ã€‚")
        elif depth_level == 3:
            prompt_parts.append("- **æ·±åº¦**: æ·±åº¦å‰–æã€‚è¯·ç»“åˆå®è§‚èƒŒæ™¯ã€ç›¸å…³æ€§åˆ†æç­‰å¤šç»´åº¦è§†è§’ï¼Œæä¾›è¯¦å°½çš„é€»è¾‘æ¨å¯¼ã€‚")
        
        return "\n".join(prompt_parts)

    def _validate_and_fix_prediction(self, result: dict, context: dict) -> dict:
        """
        é˜²å¾¡æ€§æ ¡éªŒ: ä¿®æ­£AIå¯èƒ½çš„ä½çº§é€»è¾‘é”™è¯¯ (å¹»è§‰)
        
        Checklist:
        1. åšå¤šæ—¶: SL < Entry < TP
        2. åšç©ºæ—¶: TP < Entry < SL
        3. å…¥åœºåŒºé—´: Low < High
        """
        try:
            # 1. æå–åŸºç¡€æ•°æ®
            p = result.get("prediction", "").lower()
            current_price = context.get("current_price", 0)
            
            # 2. è·å–å¹¶ä¿®æ­£å…¥åœºåŒºé—´ (é€»è¾‘åŸºç¡€)
            entry_zone = result.get("entry_zone", {})
            if not entry_zone:
                 entry_zone = {"low": current_price, "high": current_price}
            
            entry_low = float(entry_zone.get("low", current_price))
            entry_high = float(entry_zone.get("high", current_price))
            if entry_low > entry_high: entry_low, entry_high = entry_high, entry_low
            avg_entry = (entry_low + entry_high) / 2
            
            # --- æ–¹å‘ä¸€è‡´æ€§ç¡¬æ ¡éªŒ (æœ€é«˜ä¼˜å…ˆçº§) ---
            # å¦‚æœ AI è¯´çš„æ–¹å‘ä¸ç»™å‡ºçš„ TP/SL é€»è¾‘å†²çªï¼Œä»¥ä»·ä½ä¸ºå‡†
            tps = [float(x) for x in result.get("take_profit", [])]
            sl = float(result.get("stop_loss", 0))
            
            is_long = False
            is_short = False
            
            # å¦‚æœæœ‰å®Œæ•´çš„æ­¢ç›ˆç›®æ ‡ï¼Œé€šè¿‡æ­¢ç›ˆä½åˆ¤å®šçœŸå®æ–¹å‘
            is_price_long = False
            is_price_short = False
            if tps and tps[0] != avg_entry:
                if tps[0] > avg_entry:
                    is_price_long = True
                else:
                    is_price_short = True
            
            # æ–‡æœ¬è¯†åˆ«
            is_text_long = any(x in p for x in ["æ¶¨", "å¤š", "bull", "buy", "long"]) and not any(x in p for x in ["ä¸çœ‹æ¶¨", "not bull"])
            is_text_short = any(x in p for x in ["è·Œ", "ç©º", "bear", "sell", "short"]) and not any(x in p for x in ["ä¸çœ‹è·Œ", "not bear"])

            # --- å†²çªåˆ¤å®š ---
            is_long = is_price_long
            is_short = is_price_short
            
            # å¦‚æœä»·ä½æ— æ³•åˆ¤æ–­ï¼Œåˆ™é‡‡ç”¨æ–‡æœ¬
            if not is_long and not is_short:
                is_long = is_text_long
                is_short = is_text_short
            # å¦‚æœä»·ä½ä¸æ–‡æœ¬æ–¹å‘ç›¸åï¼Œä¸”ä»·ä½æœ‰æ•ˆï¼Œåˆ™è§†ä¸ºå†²çªé™çº§
            elif (is_price_long and is_text_short) or (is_price_short and is_text_long):
                logger.warning(f"æ£€æµ‹åˆ°æ–¹å‘å†²çª: æ–‡æœ¬({p}) ä¸ ä»·ä½(TP:{tps[0]}) çŸ›ç›¾ï¼Œé™çº§ä¸ºéœ‡è¡")
                is_long = is_short = False
                # BUG-5 ä¿®å¤: é™çº§æ—¶åŒæ­¥æ›´æ–° reasoning å’Œ risk_warning
                if "reasoning" not in result or not isinstance(result.get("reasoning"), list):
                    result["reasoning"] = []
                result["reasoning"].insert(0, f"âš ï¸ ç³»ç»Ÿæ£€æµ‹åˆ°æ–¹å‘å†²çª: AIæ–‡æœ¬åˆ¤æ–­ä¸ä»·ä½é€»è¾‘çŸ›ç›¾(æ–‡æœ¬:{p}, TP:{tps[0]})ï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºéœ‡è¡/è§‚æœ›ã€‚")
                if "risk_warning" not in result or not isinstance(result.get("risk_warning"), list):
                    result["risk_warning"] = []
                result["risk_warning"].insert(0, "æ–¹å‘å†²çªå·²è§¦å‘è‡ªåŠ¨é™çº§ï¼Œå»ºè®®è§‚æœ›ç­‰å¾…ä¿¡å·æ˜ç¡®")

            # æ›´æ–°ç»“æœæ ‡ç­¾ï¼Œç¡®ä¿å‰åç«¯ä¸€è‡´
            if is_long: 
                result["prediction"] = "çœ‹æ¶¨"
                logger.debug(f"æœ€ç»ˆæ–¹å‘åˆ¤å®š: çœ‹æ¶¨ [åŸºäº{'ä»·ä½' if is_price_long else 'æ–‡æœ¬'}]")
            elif is_short: 
                result["prediction"] = "çœ‹è·Œ"
                logger.debug(f"æœ€ç»ˆæ–¹å‘åˆ¤å®š: çœ‹è·Œ [åŸºäº{'ä»·ä½' if is_price_short else 'æ–‡æœ¬'}]")
            else: 
                result["prediction"] = "éœ‡è¡"
            
            # --- Anti-Chasing Logic (Smart Entry) ---
            # é˜²æ­¢è¿½æ¶¨æ€è·Œ: å¼ºåˆ¶è¦æ±‚å…¥åœºä½ä¸åŠ£äºç°ä»·å¤ªå¤š
            if is_long:
                # åšå¤š: å…¥åœºä¸èƒ½æ˜¾è‘—é«˜äºç°ä»· (å…è®¸ 0.05% çš„æ»‘ç‚¹/çªç ´ç¡®è®¤ï¼Œä½†ä¸èƒ½ç”±ç€AIä¹±æ¥)
                limit_price = current_price * 1.0005
                if entry_high > limit_price:
                    logger.warning(f"é˜²è¿½æ¶¨ä¿®æ­£(Long): Entry High({entry_high}) > Current({current_price}), å¼ºåˆ¶ä¸‹è°ƒ")
                    entry_high = current_price
                    # å¦‚æœåŒºé—´è¢«å‹æ‰äº†ï¼ŒæŠŠ low ä¹Ÿæ‹‰ä¸‹æ¥
                    if entry_low > entry_high:
                        entry_low = entry_high * 0.995 # ç»™ 0.5% åŒºé—´

            elif is_short:
                 # åšç©º: å…¥åœºä¸èƒ½æ˜¾è‘—ä½äºç°ä»·
                limit_price = current_price * 0.9995
                if entry_low < limit_price:
                    logger.warning(f"é˜²è¿½è·Œä¿®æ­£(Short): Entry Low({entry_low}) < Current({current_price}), å¼ºåˆ¶ä¸Šè°ƒ")
                    entry_low = current_price
                    # å¦‚æœåŒºé—´è¢«å‹æ‰äº†ï¼ŒæŠŠ high ä¹Ÿæ‹‰ä¸Šå»
                    if entry_high < entry_low:
                        entry_high = entry_low * 1.005 # ç»™ 0.5% åŒºé—´

            # æ›´æ–°å› result ä»·ä½ï¼Œå¹¶ç¡®è®¤ä¸ºæ ‡å‡†æ ¼å¼
            result["entry_zone"] = {"low": entry_low, "high": entry_high}
            result["stop_loss"] = sl
            result["take_profit"] = tps
            
            if not is_long and not is_short:
                  return result # éœ‡è¡/è§‚æœ›ä»…åšåŸºç¡€æ ¡éªŒåè¿”å›

            avg_entry = (entry_low + entry_high) / 2
            sl = float(result.get("stop_loss", 0))
            tps = [float(x) for x in result.get("take_profit", [])]
            
            if not tps:
                tps = [avg_entry * 1.02] if is_long else [avg_entry * 0.98] # é»˜è®¤TP
            
            # 3. é€»è¾‘ä¿®æ­£
            if is_long:
                # åšå¤šé€»è¾‘: SL < Entry
                # å°è¯•ç»“åˆ ATR è®¾å®šæ›´ç§‘å­¦çš„ SL (å¦‚æœæ²¡æœ‰ç»™å‡ºï¼Œé»˜è®¤ 1.5x ATR)
                atr = context.get("atr", 0)
                if sl >= entry_low:
                    logger.warning(f"é€»è¾‘ä¿®æ­£(Long): SL({sl}) >= Entry({entry_low}), è‡ªåŠ¨ä¸‹è°ƒSL")
                    if atr > 0:
                        sl = entry_low - (atr * 1.5)
                    else:
                        sl = entry_low * 0.98 # è‡ªåŠ¨è®¾ä¸ºå…¥åœºä¸‹æ–¹2%
                    result["stop_loss"] = sl
                    
                # åšå¤šé€»è¾‘: TP > Entry
                valid_tps = [tp for tp in tps if tp > entry_high]
                if not valid_tps:
                    logger.warning("é€»è¾‘ä¿®æ­£(Long): æ‰€æœ‰TPå‡ä½äºEntry, è‡ªåŠ¨ä¸Šè°ƒTP")
                    result["take_profit"] = [avg_entry * 1.02, avg_entry * 1.04, avg_entry * 1.06]
                else:
                    result["take_profit"] = valid_tps
                    
            elif is_short:
                # åšç©ºé€»è¾‘: SL > Entry
                atr = context.get("atr", 0)
                if sl <= entry_high:
                    logger.warning(f"é€»è¾‘ä¿®æ­£(Short): SL({sl}) <= Entry({entry_high}), è‡ªåŠ¨ä¸Šè°ƒSL")
                    if atr > 0:
                        sl = entry_high + (atr * 1.5)
                    else:
                        sl = entry_high * 1.02 # è‡ªåŠ¨è®¾ä¸ºå…¥åœºä¸Šæ–¹2%
                    result["stop_loss"] = sl
                    
                # åšç©ºé€»è¾‘: TP < Entry
                valid_tps = [tp for tp in tps if tp < entry_low]
                if not valid_tps:
                    logger.warning("é€»è¾‘ä¿®æ­£(Short): æ‰€æœ‰TPå‡é«˜äºEntry, è‡ªåŠ¨ä¸‹è°ƒTP")
                    result["take_profit"] = [avg_entry * 0.98, avg_entry * 0.96, avg_entry * 0.94]
                else:
                    result["take_profit"] = valid_tps

            # ========== V2.0 Pro: 1:1 å‡ä»“åè®®ä¸ TP1 å¼ºåˆ¶æ ¡éªŒ ==========
            sl = float(result.get("stop_loss", 0))
            avg_entry = (entry_low + entry_high) / 2
            risk_dist = abs(avg_entry - sl)
            
            if risk_dist > 0:
                # å¼ºåˆ¶è®¾ç½® TP1 ä¸º 1:1 ç›ˆäºæ¯”ä½ç½® (ä¿æœ¬åè®®)
                tp1_target = avg_entry + risk_dist if is_long else avg_entry - risk_dist
                
                # å¦‚æœ AI ç»™å‡ºçš„ TP1 ç¦» 1:1 å¤ªè¿œï¼Œå¼ºåˆ¶ä¿®æ­£
                if not tps:
                    tps = [tp1_target, tp1_target + risk_dist * 0.5, tp1_target + risk_dist * 1.5]
                else:
                    # ç¡®ä¿ç¬¬ä¸€ç›®æ ‡æ˜¯ 1:1
                    tps[0] = tp1_target
                result["take_profit"] = tps

            # --- RRR (Risk:Reward Ratio) Check (V2.0 Pro: Total RRR >= 1.5) ---
            try:
                final_tp = result["take_profit"][-1]
                reward = abs(final_tp - avg_entry)
                
                if risk_dist > 0:
                    rrr = reward / risk_dist
                    if rrr < 1.5:
                        logger.warning(f"æœ€ç»ˆRRRè¿‡ä½({rrr:.2f} < 1.5), å°è¯•ä¸Šè°ƒæœ«å°¾æ­¢ç›ˆæˆ–é™çº§")
                        if rrr < 1.0:
                            result["prediction"] = "éœ‡è¡"
                            result["reasoning"].insert(0, f"âš ï¸ ä¸¥é‡é£é™©: æ€»ç›ˆäºæ¯”({rrr:.2f})ä¸è¶³1.0ï¼Œç­–ç•¥æ— æ•ˆï¼Œå·²è‡ªåŠ¨é™çº§ã€‚")
                            return result
                        else:
                            # å°è¯•å¾®è°ƒ TP ä»¥ç¬¦åˆ 1.5
                            if is_long: result["take_profit"][-1] = avg_entry + risk_dist * 1.6
                            else: result["take_profit"][-1] = avg_entry - risk_dist * 1.6
                            result["reasoning"].insert(0, f"ğŸ’¡ ç­–ç•¥ä¼˜åŒ–: å·²è‡ªåŠ¨è°ƒæ•´æ­¢ç›ˆä½ä»¥ç¡®ä¿æ”¶ç›Šé£é™©æ¯” > 1.5ã€‚")
            except Exception as e:
                logger.error(f"RRRè®¡ç®—é”™è¯¯: {e}")

            # ========== V2.0 Pro: VPVR çœŸç©ºåŒºæ­¢æŸé¿é›· ==========
            vpvr = context.get("vpvr", {})
            lvn = vpvr.get("vacuum_lvn")
            poc = vpvr.get("poc_hvn")
            if lvn and sl:
                # å¦‚æœæ­¢æŸä½è½åœ¨çœŸç©ºåŒºé™„è¿‘ (Â±0.5% ATR)ï¼Œåˆ™è®¤ä¸ºä¸å®‰å…¨
                atr = context.get("atr", 0) or (avg_entry * 0.01)
                if abs(sl - lvn) < atr * 0.5:
                    logger.warning(f"æ­¢æŸç¢°æ’çœŸç©ºåŒº(LVN:{lvn}), è§¦å‘é˜²æ‰«æŸä¿®æ­£")
                    # å°†æ­¢æŸå‘ POC æˆ– è¿œç¦»çœŸç©ºåŒºçš„æ–¹å‘ç§»åŠ¨
                    if is_long:
                        sl = min(sl, lvn) - atr * 0.5 # å‘ä¸‹ç§»ç¦»çœŸç©ºåŒº
                    else:
                        sl = max(sl, lvn) + atr * 0.5 # å‘ä¸Šç§»ç¦»çœŸç©ºåŒº
                    result["stop_loss"] = sl
                    result["reasoning"].append(f"ğŸ›¡ï¸ æ­¢æŸä¿æŠ¤: æ£€æµ‹åˆ°åŸæ­¢æŸç‚¹å¤„äºæˆäº¤çœŸç©ºåŒº(LVN)ï¼Œå·²è‡ªåŠ¨ä¿®æ­£ä»¥é˜²ç¬é—´æ‰«æŸã€‚")

            # ========== V2.0 Pro: SMC æœºæ„é”šå®šæç¤º ==========
            obs = context.get("smc", {}).get("order_blocks", [])
            for ob in obs:
                # å¦‚æœå…¥åœºåŒºé—´è§¦ç¢°äº† OB
                if (ob["type"] == "bullish" and is_long) or (ob["type"] == "bearish" and is_short):
                    if entry_low <= ob["top"] and entry_high >= ob["bottom"]:
                        result["summary"] = f"ğŸ¯ [SMCé”šå®š] {result.get('summary', '')} (å…¥åœºåŒºåŸŸä¸æœºæ„è®¢å•å—é‡åˆ)"
                        break

            # 4. æ—¶æ•ˆæ€§æ£€æŸ¥: å¦‚æœå½“å‰ä»·æ ¼å·²ç»çªç ´äº† TP1
            tps_final = result.get("take_profit", [])
            if tps_final:
                tp1 = float(tps_final[0])
                if is_long and current_price >= tp1:
                    result["reasoning"].insert(0, f"âš ï¸ æç¤º: ç°ä»· ({current_price}) å·²è§¦åŠæˆ–çªç ´ç›®æ ‡ TP1 ({tp1})ï¼Œå»ºè®®ç­‰å¾…å›è°ƒå…¥åœºã€‚")
                elif is_short and current_price <= tp1:
                    result["reasoning"].insert(0, f"âš ï¸ æç¤º: ç°ä»· ({current_price}) å·²è§¦åŠæˆ–çªç ´ç›®æ ‡ TP1 ({tp1})ï¼Œå»ºè®®ç­‰å¾…åå¼¹å…¥åœºã€‚")

            # ========== å¢å¼º: TPè·ç¦»åˆç†æ€§æ£€æŸ¥ (å¹»è§‰æ£€æµ‹) ==========
            atr = context.get("atr", 0)
            if atr > 0 and tps_final:
                for i, tp in enumerate(tps_final):
                    tp_distance = abs(float(tp) - avg_entry)
                    if tp_distance > atr * 5:
                        logger.warning(f"å¹»è§‰ä¿®æ­£: TP{i+1}({tp}) è·ç¦»å…¥åœºä½è¿‡è¿œ ({tp_distance/atr:.1f}x ATR), é™åˆ¶ä¸º 3x ATR")
                        if is_long:
                            tps_final[i] = avg_entry + atr * 3 * (i + 1)
                        else:
                            tps_final[i] = avg_entry - atr * 3 * (i + 1)
                result["take_profit"] = tps_final
            
            # ========== å¢å¼º: å…¥åœºåŒºé—´å®½åº¦æ£€æŸ¥ ==========
            entry_width = abs(entry_high - entry_low)
            if atr > 0 and entry_width > atr * 2:
                logger.warning(f"å¹»è§‰ä¿®æ­£: å…¥åœºåŒºé—´è¿‡å®½ ({entry_width:.2f} > 2*ATR={atr*2:.2f}), æ”¶çª„è‡³ 0.5*ATR")
                mid_entry = (entry_low + entry_high) / 2
                result["entry_zone"] = {
                    "low": mid_entry - atr * 0.25,
                    "high": mid_entry + atr * 0.25
                }

            # ========== å¢å¼º: ç½®ä¿¡åº¦ä¸Šä¸‹æ–‡è‡ªåŠ¨æ ¡éªŒ (P4 åŠ ä¸¥) ==========
            confidence = result.get("confidence", 50)
            conflicts = context.get("signal_conflicts", [])
            if "risk_warning" not in result or not isinstance(result.get("risk_warning"), list):
                result["risk_warning"] = []
            if conflicts and len(conflicts) >= 3 and confidence > 60:
                old_conf = confidence
                confidence = min(confidence, 60)
                result["confidence"] = confidence
                logger.warning(f"ç½®ä¿¡åº¦æ ¡æ­£: {old_conf}% -> {confidence}% (å­˜åœ¨{len(conflicts)}ä¸ªä¿¡å·å†²çª)")
                result["risk_warning"].append(f"æŒ‡æ ‡ä¿¡å·å†²çªè¾ƒå¤š({len(conflicts)}ä¸ª), ç½®ä¿¡åº¦å·²è‡ªåŠ¨é™è‡³{confidence}%")
            elif conflicts and len(conflicts) >= 2 and confidence > 70:
                old_conf = confidence
                confidence = min(confidence, 70)
                result["confidence"] = confidence
                logger.warning(f"ç½®ä¿¡åº¦æ ¡æ­£: {old_conf}% -> {confidence}% (å­˜åœ¨{len(conflicts)}ä¸ªä¿¡å·å†²çª)")
                result["risk_warning"].append(f"å­˜åœ¨{len(conflicts)}ä¸ªä¿¡å·å†²çª, ç½®ä¿¡åº¦å·²é™è‡³{confidence}%")
            elif conflicts and len(conflicts) >= 1 and confidence > 85:
                old_conf = confidence
                confidence = min(confidence, 80)
                result["confidence"] = confidence
                logger.warning(f"ç½®ä¿¡åº¦æ ¡æ­£: {old_conf}% -> {confidence}% (å­˜åœ¨{len(conflicts)}ä¸ªä¿¡å·å†²çª)")

            # ========== BUG-2/BUG-4: key_levels æ ¡éªŒä¸é”šå®š ==========
            result = self._validate_key_levels(result, context)

            # ========== BUG-1: reasoning æ–‡æœ¬é€»è¾‘æ ¡éªŒ ==========
            result = self._sanitize_reasoning(result, context)

            return result
            
        except Exception as e:
            logger.error(f"é€»è¾‘æ ¡éªŒå‘ç”Ÿé”™è¯¯: {e}, è¿”å›åŸå§‹ç»“æœ")
            return result

    def _validate_key_levels(self, result: dict, context: dict) -> dict:
        """
        æ ¡éªŒ key_levels åˆç†æ€§ (BUG-2 + BUG-4)
        
        1. å¼ºåˆ¶è¦†ç›– current_price ä¸ºçœŸå®å€¼
        2. ç¡®ä¿ support < current_price < resistance
        3. å¦‚æœ‰ pivot_pointsï¼Œç”¨ Pivot é”šå®š
        """
        try:
            current_price = context.get("current_price", 0)
            if not current_price:
                return result

            kl = result.get("key_levels", {})
            if not isinstance(kl, dict):
                kl = {}

            # BUG-4: å¼ºåˆ¶è¦†ç›– current_price
            kl["current_price"] = current_price

            # BUG-2: ç¡®ä¿ support < current_price < resistance
            strong_support = float(kl.get("strong_support", 0))
            strong_resistance = float(kl.get("strong_resistance", 0))
            weak_support = float(kl.get("weak_support", 0))
            weak_resistance = float(kl.get("weak_resistance", 0))

            # ä¿®æ­£: æ”¯æ’‘ä½ä¸èƒ½é«˜äºå½“å‰ä»·
            if strong_support > 0 and strong_support >= current_price:
                logger.warning(f"key_levelsä¿®æ­£: strong_support({strong_support}) >= å½“å‰ä»·({current_price}), è‡ªåŠ¨ä¸‹è°ƒ")
                kl["strong_support"] = current_price * 0.95
            if weak_support > 0 and weak_support >= current_price:
                logger.warning(f"key_levelsä¿®æ­£: weak_support({weak_support}) >= å½“å‰ä»·({current_price}), è‡ªåŠ¨ä¸‹è°ƒ")
                kl["weak_support"] = current_price * 0.98

            # ä¿®æ­£: é˜»åŠ›ä½ä¸èƒ½ä½äºå½“å‰ä»·
            if strong_resistance > 0 and strong_resistance <= current_price:
                logger.warning(f"key_levelsä¿®æ­£: strong_resistance({strong_resistance}) <= å½“å‰ä»·({current_price}), è‡ªåŠ¨ä¸Šè°ƒ")
                kl["strong_resistance"] = current_price * 1.05
            if weak_resistance > 0 and weak_resistance <= current_price:
                logger.warning(f"key_levelsä¿®æ­£: weak_resistance({weak_resistance}) <= å½“å‰ä»·({current_price}), è‡ªåŠ¨ä¸Šè°ƒ")
                kl["weak_resistance"] = current_price * 1.02

            # å¦‚æœ‰ pivot_pointsï¼Œåšäº¤å‰éªŒè¯
            pivot = context.get("pivot_points", {})
            if pivot:
                classic = pivot.get("classic", {})
                pivot_s1 = classic.get("s1")
                pivot_r1 = classic.get("r1")
                if pivot_s1 and strong_support > 0:
                    # å¦‚æœ AI ç»™çš„æ”¯æ’‘ä¸ Pivot S1 åå·®è¶…è¿‡ 5%ï¼Œå‘å‡ºè­¦å‘Š
                    deviation = abs(strong_support - pivot_s1) / current_price
                    if deviation > 0.05:
                        logger.warning(f"key_levelsåå·®: AI support({strong_support}) vs Pivot S1({pivot_s1}), åå·®{deviation:.1%}")

            result["key_levels"] = kl

        except Exception as e:
            logger.error(f"key_levelsæ ¡éªŒé”™è¯¯: {e}")

        return result

    def _sanitize_reasoning(self, result: dict, context: dict) -> dict:
        """
        æ ¡éªŒ reasoning å’Œ risk_warning ä¸­çš„ä»·æ ¼é€»è¾‘ (BUG-1)
        
        æ‰«ææ–‡æœ¬ä¸­çš„ä»·æ ¼å¼•ç”¨ï¼Œæ£€æµ‹ä¸ current_price çŸ›ç›¾çš„è¡¨è¿°ï¼š
        - "è·Œç ´æ”¯æ’‘X" ä½† X > current_price â†’ ä¿®æ­£ä¸º "å·²è·Œç ´æ”¯æ’‘X"
        - "çªç ´é˜»åŠ›X" ä½† X < current_price â†’ ä¿®æ­£ä¸º "å·²çªç ´é˜»åŠ›X"
        """
        try:
            current_price = context.get("current_price", 0)
            if not current_price:
                return result

            import re

            def fix_price_logic(text: str) -> str:
                """ä¿®æ­£å•æ¡æ–‡æœ¬ä¸­çš„ä»·æ ¼é€»è¾‘çŸ›ç›¾"""
                # æ¨¡å¼1: "å‘ä¸‹è·Œç ´æ”¯æ’‘X" / "è·Œç ´æ”¯æ’‘X" ä½† X > current_price
                pattern_break_support = re.compile(
                    r'(å‘ä¸‹)?è·Œç ´(æ”¯æ’‘|æ”¯æ’‘ä½)?\s*([\d,]+\.?\d*)'
                )
                for m in pattern_break_support.finditer(text):
                    price_str = m.group(3).replace(',', '')
                    try:
                        price_val = float(price_str)
                        if price_val > current_price:
                            old = m.group(0)
                            new = f"å·²è·Œç ´å‰æ”¯æ’‘{price_str}(å½“å‰ä»·{current_price:.2f}å·²åœ¨å…¶ä¸‹æ–¹)"
                            text = text.replace(old, new)
                            logger.warning(f"reasoningä¿®æ­£: '{old}' â†’ '{new}'")
                    except ValueError:
                        pass

                # æ¨¡å¼2: "çªç ´é˜»åŠ›X" / "å‘ä¸Šçªç ´X" ä½† X < current_price  
                pattern_break_resistance = re.compile(
                    r'(å‘ä¸Š)?çªç ´(é˜»åŠ›|é˜»åŠ›ä½)?\s*([\d,]+\.?\d*)'
                )
                for m in pattern_break_resistance.finditer(text):
                    price_str = m.group(3).replace(',', '')
                    try:
                        price_val = float(price_str)
                        if price_val < current_price:
                            old = m.group(0)
                            new = f"å·²çªç ´å‰é˜»åŠ›{price_str}(å½“å‰ä»·{current_price:.2f}å·²åœ¨å…¶ä¸Šæ–¹)"
                            text = text.replace(old, new)
                            logger.warning(f"reasoningä¿®æ­£: '{old}' â†’ '{new}'")
                    except ValueError:
                        pass

                # æ¨¡å¼3: "æ”¯æ’‘X" ä½† X > current_price (æ”¯æ’‘ä½åº”ä½äºå½“å‰ä»·)
                # æ’é™¤å·²è¢«æ¨¡å¼1ä¿®æ­£è¿‡çš„æ–‡æœ¬ (å«"å‰æ”¯æ’‘"/"å·²è·Œç ´")
                pattern_support_above = re.compile(
                    r'(?<!å‰)æ”¯æ’‘(ä½)?[ï¼š:]?\s*([\d,]+\.?\d*)'
                )
                for m in pattern_support_above.finditer(text):
                    price_str = m.group(2).replace(',', '')
                    try:
                        price_val = float(price_str)
                        if price_val > current_price * 1.01:  # å®¹å¿1%è¯¯å·®
                            old = m.group(0)
                            new = f"å‰æ”¯æ’‘ä½{price_str}(å·²å¤±å®ˆï¼Œå½“å‰ä»·åœ¨å…¶ä¸‹æ–¹)"
                            text = text.replace(old, new)
                            logger.warning(f"reasoningä¿®æ­£: æ”¯æ’‘ä½({price_val})é«˜äºå½“å‰ä»·({current_price})")
                    except ValueError:
                        pass

                return text

            # å¤„ç† reasoning åˆ—è¡¨
            reasoning = result.get("reasoning", [])
            if isinstance(reasoning, list):
                result["reasoning"] = [fix_price_logic(r) for r in reasoning]

            # å¤„ç† risk_warning åˆ—è¡¨
            risk_warning = result.get("risk_warning", [])
            if isinstance(risk_warning, list):
                result["risk_warning"] = [fix_price_logic(r) for r in risk_warning]

        except Exception as e:
            logger.error(f"reasoningæ ¡éªŒé”™è¯¯: {e}")

        return result

    def _parse_response(self, response_text: str, context_data: Optional[dict] = None) -> AnalysisResult:
        """
        è§£æAPIå“åº”ä¸ºç»“æ„åŒ–ç»“æœ
        
        å¤„ç†DeepSeekè¿”å›çš„JSONæ–‡æœ¬ï¼Œè½¬æ¢ä¸ºAnalysisResultå¯¹è±¡ã€‚
        
        Args:
            response_text: APIè¿”å›çš„åŸå§‹æ–‡æœ¬ï¼ˆåº”ä¸ºJSONæ ¼å¼ï¼‰
            context_data: åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆç”¨äºæ ¡éªŒï¼‰
        
        Returns:
            AnalysisResult: è§£æåçš„åˆ†æç»“æœå¯¹è±¡
        
        Raises:
            ValueError: JSONè§£æå¤±è´¥æˆ–æ ¼å¼ä¸ç¬¦åˆé¢„æœŸæ—¶æŠ›å‡º
        """
        try:
            # å¢å¼ºçš„JSONæå–é€»è¾‘ (é€‚é… R1/Chat å„ç§è¾“å‡ºæƒ…å†µ)
            text = response_text.strip()
            
            # [æ–°å¢] ä¸“é—¨å¤„ç† DeepSeek R1 çš„ <think> æ ‡ç­¾
            # ç§»é™¤æ€ç»´é“¾å†…å®¹ï¼Œåªä¿ç•™æœ€ç»ˆ JSON
            if "<think>" in text:
                import re
                # åŒ¹é… <think>...<think> (å®Œæ•´) æˆ– <think>... (æˆªæ–­)
                # re.DOTALL è®© . åŒ¹é…æ¢è¡Œç¬¦
                text = re.sub(r"<think>.*?(?:</think>|$)", "", text, flags=re.DOTALL).strip()

            # 1. å°è¯•ç›´æ¥è§£æ
            try:
                data = json.loads(text)
            except json.JSONDecodeError:
                # 2. å°è¯•å¯»æ‰¾ç¬¬ä¸€ä¸ª '{' å¹¶ä½¿ç”¨ raw_decode è§£æ
                start_idx = text.find('{')
                if start_idx != -1:
                    try:
                        decoder = json.JSONDecoder()
                        data, _ = decoder.raw_decode(text, start_idx)
                    except json.JSONDecodeError as e:
                        # å¦‚æœ raw_decode å¤±è´¥ï¼Œå°è¯•æœ€åçš„æ‰‹æ®µï¼šæ‰‹åŠ¨æå–æœ€å¤–å±‚å¤§æ‹¬å·
                        # è¿™ä¸»è¦å¤„ç† raw_decode å¯èƒ½å› ä¸ºéæ ‡å‡†æ ¼å¼å¤±è´¥çš„æƒ…å†µ
                        logger.warning(f"raw_decodeå¤±è´¥ï¼Œå°è¯•æš´åŠ›æå–: {e}")
                        
                        logger.error(f"raw_decodeå¤±è´¥ï¼Œå°è¯•æš´åŠ›æå–: {e} | å“åº”å‰500å­—: {text[:500]}")

                        end_idx = text.rfind('}')
                        if end_idx != -1 and end_idx > start_idx:
                            sub_text = text[start_idx : end_idx + 1]
                            try:
                                data = json.loads(sub_text)
                            except:
                                # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é”™è¯¯ (å¦‚åŒä¸º False, å°¾éƒ¨é€—å·)
                                # è¿™é‡Œå¯ä»¥å¼•å…¥æ›´å¤æ‚çš„ä¿®å¤é€»è¾‘ï¼Œæˆ–è€…ç›´æ¥æŠ¥é”™
                                raise ValueError(f"æ— æ³•è§£ææå–çš„JSONç‰‡æ®µ: {e}")
                        else:
                            raise ValueError("æ— æ³•æ‰¾åˆ°é—­åˆçš„å¤§æ‹¬å·")
                else:
                    logger.error(f"å“åº”ä¸­æœªæ‰¾åˆ°JSONå¯¹è±¡èµ·å§‹ç¬¦ | å“åº”å‰500å­—: {text[:500]}")
                    raise ValueError("å“åº”ä¸­æœªæ‰¾åˆ°JSONå¯¹è±¡èµ·å§‹ç¬¦ '{'")
            
            # è¡¥é½å¯èƒ½ç¼ºå¤±çš„å­—æ®µ (Pydantic æ ¡éªŒè¦æ±‚)
            if "analysis_time" not in data:
                data["analysis_time"] = datetime.now().isoformat()
            if "timeframe" not in data and context_data:
                data["timeframe"] = context_data.get("timeframe", "4h")
            
            # ========== æ–°å¢: é˜²å¾¡æ€§é€»è¾‘æ ¡éªŒä¸ä¿®æ­£ ==========
            if context_data:
                data = self._validate_and_fix_prediction(data, context_data)
            # ============================================

            # éªŒè¯å¹¶åˆ›å»ºç»“æœå¯¹è±¡
            result = AnalysisResult(**data)
            
            logger.info(
                f"åˆ†æç»“æœè§£ææˆåŠŸ | {result.symbol} | "
                f"é¢„æµ‹: {result.prediction} | ç½®ä¿¡åº¦: {result.confidence}%"
            )
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}\nåŸå§‹å“åº”: {response_text[:500]}...")
            raise ValueError(f"AIå“åº”æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æä¸ºJSON: {e}")
        except Exception as e:
            logger.error(f"å“åº”å¤„ç†å¤±è´¥: {e}")
            raise ValueError(f"å“åº”å¤„ç†å¤±è´¥: {e}")
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        # C-3 ä¿®å¤: å‡å°‘é‡è¯•æ¬¡æ•°(5â†’3)ï¼Œç§»é™¤ ValueError é˜²æ­¢ JSON è§£æé”™è¯¯æ— é™é‡è¯•
        # å†…éƒ¨å·²æœ‰ R1â†’V3 é™çº§å¾ªç¯(2æ¬¡)ï¼Œå¤–å±‚3æ¬¡æ€»è®¡æœ€å¤š6æ¬¡ API è°ƒç”¨
        retry=retry_if_exception_type((APITimeoutError, APIConnectionError, EmptyResponseError, APIError))
    )
    async def analyze_market(
        self,
        symbol: str,
        context_data: dict[str, Any]
    ) -> AnalysisResult:
        """
        åˆ†æå¸‚åœºå¹¶ç”Ÿæˆé¢„æµ‹
        
        æ ¸å¿ƒæ–¹æ³•ï¼šæ¥æ”¶äº¤æ˜“å¯¹ç¬¦å·å’Œä¸Šä¸‹æ–‡æ•°æ®ï¼Œè°ƒç”¨DeepSeek APIè¿›è¡Œåˆ†æï¼Œ
        è¿”å›ç»“æ„åŒ–çš„åˆ†æç»“æœã€‚
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼Œå¦‚ "ETHUSDT", "BTCUSDT"
            context_data: ä¸Šä¸‹æ–‡æ•°æ®å­—å…¸ï¼ŒåŒ…å«Kçº¿æ‘˜è¦ã€æŠ€æœ¯æŒ‡æ ‡ã€æ–°é—»ç­‰ä¿¡æ¯
        
        Returns:
            AnalysisResult: åŒ…å«é¢„æµ‹æ–¹å‘ã€ç½®ä¿¡åº¦ã€é€»è¾‘é“¾ã€é£é™©è­¦å‘Šç­‰çš„åˆ†æç»“æœ
        
        Raises:
            APIError: DeepSeek APIè°ƒç”¨å¤±è´¥
            APITimeoutError: APIè¯·æ±‚è¶…æ—¶ï¼ˆä¼šè‡ªåŠ¨é‡è¯•3æ¬¡ï¼‰
            APIConnectionError: ç½‘ç»œè¿æ¥é”™è¯¯ï¼ˆä¼šè‡ªåŠ¨é‡è¯•3æ¬¡ï¼‰
            ValueError: å“åº”è§£æå¤±è´¥
            EmptyResponseError: APIè¿”å›ç©ºå†…å®¹ï¼ˆä¼šè‡ªåŠ¨é‡è¯•3æ¬¡ï¼‰
        """
        logger.info(f"å¼€å§‹åˆ†æ {symbol}...")
        
        # [é…ç½®åŠ¨æ€è¦†ç›–]
        # 1. å…ˆç¡®å®šä½¿ç”¨çš„æ¨¡å‹
        current_model = self.model
        current_system_prompt = self.system_prompt
        
        prefs = context_data.get("user_preferences", {})
        if prefs:
            if prefs.get("model"):
                current_model = prefs["model"]
                logger.info(f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šæ¨¡å‹: {current_model}")
            
            # CRIT-1 Fix: Initialize prefs early to ensure it's available for metadata injection later
            # This block was moved up, but the original `prefs` initialization was already there.
            # The instruction's `prefs.get("promptTemplate")` uses a different key casing.
            # Sticking to `prompt_template` for consistency with existing code.
            if prefs.get("prompt_template"):
                custom_prompt = prefs["prompt_template"]
                if len(custom_prompt) > 50: # ç®€å•é•¿åº¦æ£€æŸ¥
                    current_system_prompt = custom_prompt
                    logger.info("ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿")

        # 2. è‡ªåŠ¨é™çº§ç­–ç•¥å¾ªç¯ (R1 -> V3)
        # å¦‚æœ R1 å¤±è´¥ (è¶…æ—¶/æˆªæ–­/è§£æé”™è¯¯)ï¼Œè‡ªåŠ¨é™çº§åˆ° V3
        active_model = current_model
        # ä¿å­˜åŸå§‹ System Prompt ä»¥ä¾¿é™çº§æ—¶æ¢å¤
        base_system_prompt = current_system_prompt

        for attempt in range(2):
            try:
                # --- A. æ ¹æ®æ¨¡å‹æ„å»º Prompt ---
                temp_system_prompt = base_system_prompt
                
                if "reasoner" in active_model:
                    # R1 æ¨¡å‹: ä½¿ç”¨æ¨ç†ä¸“ç”¨ Prompt
                    user_prompt = self._build_reasoner_prompt(symbol, context_data)
                    # R1 å¤ç”¨å®Œæ•´ä¸­æ–‡ç³»ç»Ÿæç¤ºè¯ï¼ˆé™¤éç”¨æˆ·è‡ªå®šä¹‰ï¼‰
                    # ä¿®å¤: ä¸å†ä½¿ç”¨è‹±æ–‡ç®€åŒ–ç‰ˆï¼Œé¿å…ç³»ç»ŸæŒ‡ä»¤ä¸ç”¨æˆ·æç¤ºè¯è¯­è¨€ä¸ä¸€è‡´
                else:
                    # V3/Chat æ¨¡å‹: ä½¿ç”¨æ ‡å‡† Prompt
                    user_prompt = self._build_user_prompt(symbol, context_data)

                logger.debug(f"Promptæ„å»ºå®Œæˆ (Attempt {attempt+1}) | æ¨¡å‹: {active_model} | SystemPrompté•¿åº¦: {len(temp_system_prompt)}")
                
                # --- B. è®¡ç®— Max Tokens ---
                request_max_tokens = self.max_tokens
                if "reasoner" in active_model and request_max_tokens < 8000:
                    request_max_tokens = 8192
                    logger.info(f"ä¸º R1 æ¨¡å‹è‡ªé€‚åº”è°ƒæ•´ Max Tokens: {request_max_tokens}")

                # --- C. è°ƒç”¨ API ---
                response = await self.client.chat.completions.create(
                    model=active_model,
                    messages=[
                        {"role": "system", "content": temp_system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=self.temperature,
                    max_tokens=request_max_tokens
                )
                
                # --- D. éªŒè¯å“åº” ---
                if not response.choices:
                    raise EmptyResponseError("API returned no choices")
                
                choice = response.choices[0]
                if not choice.message.content:
                    reason = choice.finish_reason
                    if reason == 'length':
                        raise EmptyResponseError(f"API output truncated (Max tokens reached). model={active_model}")
                    raise EmptyResponseError(f"API returned empty content (Finish Reason: {reason})")
                    
                response_text = choice.message.content
                logger.debug(f"APIå“åº”æ¥æ”¶æˆåŠŸï¼Œé•¿åº¦: {len(response_text)} å­—ç¬¦")
                
                # --- E. è§£æå“åº” ---
                result = self._parse_response(response_text, context_data)
                
                # --- F. æ³¨å…¥å…ƒæ•°æ® ---
                result.ai_model = active_model
                result.ai_prompt_template = "è‡ªå®šä¹‰æ¨¡æ¿" if prefs.get("prompt_template") else ("ç³»ç»Ÿé»˜è®¤(R1)" if "reasoner" in active_model else "ç³»ç»Ÿé»˜è®¤")
                
                # æ³¨å…¥é€ä¼ ä¸Šä¸‹æ–‡
                if context_data.get("trend_context"):
                    result.trend_context = context_data["trend_context"]
                if context_data.get("order_book"):
                    result.order_book_context = context_data["order_book"]
                
                return result

            except (EmptyResponseError, ValueError, APITimeoutError, APIConnectionError, APIError) as e:
                logger.warning(f"æ¨¡å‹ {active_model} è°ƒç”¨å¤±è´¥: {e}")
                
                # å¦‚æœæ˜¯ R1 ä¸”æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œåˆ™é™çº§
                if "reasoner" in active_model and attempt == 0:
                    logger.warning(">>> æ­£åœ¨è‡ªåŠ¨é™çº§åˆ° DeepSeek-Chat (V3) æ¨¡å‹é‡è¯•...")
                    active_model = "deepseek-chat"
                    continue
                
                # å¦åˆ™æŠ›å‡ºå¼‚å¸¸ç»™ä¸Šå±‚å¤„ç†
                raise
            
        # (å…¶ä½™å¼‚å¸¸å¤„ç†å·²åˆå¹¶è‡³ä¸Šæ–¹å¾ªç¯)
    
    async def analyze_market_stream(
        self,
        symbol: str,
        context_data: dict[str, Any]
    ):
        """
        æµå¼åˆ†æå¸‚åœºï¼ˆå¼‚æ­¥ç”Ÿæˆå™¨ï¼‰
        
        æ”¯æŒæµå¼è¾“å‡ºåˆ†æè¿‡ç¨‹ï¼Œé€‚ç”¨äºå‰ç«¯å®æ—¶å±•ç¤ºã€‚
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            context_data: ä¸Šä¸‹æ–‡æ•°æ®
        
        Yields:
            str: åˆ†æå†…å®¹ç‰‡æ®µ
        
        Example:
            >>> async for chunk in analyst.analyze_market_stream("ETHUSDT", context):
            ...     print(chunk, end="", flush=True)
        """
        # [é…ç½®åŠ¨æ€è¦†ç›–]
        # 1. å…ˆç¡®å®šä½¿ç”¨çš„æ¨¡å‹
        current_model = self.model
        current_system_prompt = self.system_prompt
        
        prefs = context_data.get("user_preferences", {})
        
        if prefs:
            if prefs.get("model"):
                current_model = prefs["model"]
                logger.info(f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šæ¨¡å‹ (æµå¼): {current_model}")
            
            # Sticking to `prompt_template` for consistency with existing code.
            if prefs.get("prompt_template"):
                custom_prompt = prefs["prompt_template"]
                if len(custom_prompt) > 50:
                    current_system_prompt = custom_prompt
                    logger.info("ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿ (æµå¼)")

        # 2. æ ¹æ®æ¨¡å‹é€‰æ‹© Prompt æ„å»ºå™¨
        if "reasoner" in current_model:
            # R1 æ¨¡å‹
            user_prompt = self._build_reasoner_prompt(symbol, context_data)
            # P1 ä¿®å¤: ä¸å†è¦†ç›–ä¸ºè‹±æ–‡ç®€åŒ–ç‰ˆï¼Œç»Ÿä¸€ä½¿ç”¨å®Œæ•´ä¸­æ–‡ SYSTEM_PROMPT
            # ä¸éæµå¼ analyze_market ä¿æŒä¸€è‡´
        else:
            # V3/Chat æ¨¡å‹
            user_prompt = self._build_user_prompt(symbol, context_data)
            
        try:
            # R1 æ¨¡å‹é€šå¸¸éœ€è¦æ›´é•¿çš„ Token çª—å£è¿›è¡Œæ¨ç†
            request_max_tokens = self.max_tokens
            if "reasoner" in current_model and request_max_tokens < 8000:
                request_max_tokens = 8192

            stream = await self.client.chat.completions.create(
                model=current_model,
                messages=[
                    {"role": "system", "content": current_system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=self.temperature,
                max_tokens=request_max_tokens,
                stream=True
            )
            
            # MED-6 Fix: Accumulate full response for caching
            full_content = []
            
            async for chunk in stream:
                # CRIT-2 Fix: Check if choices exists and is not empty
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    yield content
                    full_content.append(content)
            
            # MED-6 Fix: Cache the complete result to avoid double-spending API credits
            if full_content:
                complete_text = "".join(full_content)
                try:
                    # Parse to ensure it's valid JSON before caching
                    result = self._parse_response(complete_text, context_data)
                    
                    # Inject config metadata same as analyze_market
                    result.ai_model = current_model
                    result.ai_prompt_template = "è‡ªå®šä¹‰æ¨¡æ¿" if prefs and prefs.get("prompt_template") else "ç³»ç»Ÿé»˜è®¤"
                    
                    if context_data.get("trend_context"):
                        result.trend_context = context_data["trend_context"]
                    if context_data.get("order_book"):
                        result.order_book_context = context_data["order_book"]
                        
                    # Save to cache
                    # Fix Circular Import: Import locally
                    from app.services.cache_service import get_cached_analyzer
                    await get_cached_analyzer().cache_analysis(symbol, result)
                    logger.info(f"Stream analysis cached for {symbol}")
                except Exception as e:
                    logger.warning(f"Failed to cache stream result: {e}")
                    
        except Exception as e:
            logger.error(f"DeepSeekæµå¼åˆ†æå¤±è´¥: {e}")
            yield f"\n[ERROR] åˆ†æè¯·æ±‚å¤±è´¥: {str(e)}"
            raise


# ============================================================
# ä¾¿æ·å·¥å‚å‡½æ•°
# ============================================================

def create_analyst(api_key: Optional[str] = None) -> DeepSeekAnalyst:
    """
    åˆ›å»ºDeepSeekåˆ†æå¸ˆå®ä¾‹çš„ä¾¿æ·å·¥å‚å‡½æ•°
    
    Args:
        api_key: å¯é€‰çš„APIå¯†é’¥ï¼Œä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
    
    Returns:
        DeepSeekAnalyst: åˆå§‹åŒ–å®Œæˆçš„åˆ†æå¸ˆå®ä¾‹
    """
    return DeepSeekAnalyst(api_key=api_key)


# ============================================================
# å…¨å±€å•ä¾‹
# ============================================================

_analyst: Optional[DeepSeekAnalyst] = None


def get_analyst() -> DeepSeekAnalyst:
    """è·å–å…¨å±€åˆ†æå¸ˆå•ä¾‹"""
    global _analyst
    if _analyst is None:
        _analyst = create_analyst()
    return _analyst


def reset_analyst():
    """é‡ç½®å…¨å±€åˆ†æå¸ˆå•ä¾‹ï¼Œç”¨äºé…ç½®å˜æ›´ååˆ·æ–°"""
    global _analyst
    _analyst = None
    logger.info("DeepSeek åˆ†æå¸ˆå•ä¾‹å·²é‡ç½®")


# ============================================================
# æ¨¡å—æµ‹è¯•å…¥å£
# ============================================================

if __name__ == "__main__":
    # ç®€å•çš„æ¨¡å—æµ‹è¯•
    import asyncio
    
    # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡æ•°æ®
    test_context = {
        "kline_summary": """
        æœ€è¿‘24å°æ—¶ETHèµ°åŠ¿ï¼š
        - å¼€ç›˜ä»·: 2580 USDT
        - æœ€é«˜ä»·: 2695 USDT
        - æœ€ä½ä»·: 2550 USDT
        - å½“å‰ä»·: 2650 USDT
        - æ¶¨å¹…: +2.7%
        - å½¢æˆä¸€ä¸ªçœ‹æ¶¨åæ²¡å½¢æ€ï¼Œçªç ´å‰é«˜
        """,
        "current_price": 2650,
        "funding_rate": 0.0012,
        "rsi": 58.5,
        "macd": "MACDé‡‘å‰ï¼ŒDIFä¸Šç©¿DEAï¼ŒæŸ±çŠ¶å›¾ç”±è´Ÿè½¬æ­£",
        "ma_status": "ä»·æ ¼ç«™ä¸ŠMA20(2580)å’ŒMA50(2520)ï¼Œå‡çº¿å¤šå¤´æ’åˆ—",
        "news_headlines": [
            "ä»¥å¤ªåŠETFå•æ—¥å‡€æµå…¥1.5äº¿ç¾å…ƒï¼Œåˆ›è¿‘æœŸæ–°é«˜",
            "Vitalikå‘å¸ƒEIP-7702ææ¡ˆï¼Œä¼˜åŒ–è´¦æˆ·æŠ½è±¡ä½“éªŒ",
            "é“¾ä¸Šæ•°æ®æ˜¾ç¤ºå·¨é²¸åœ°å€24å°æ—¶å¢æŒ5ä¸‡ETH"
        ],
        "market_sentiment": "ææ…Œè´ªå©ªæŒ‡æ•°: 65 (è´ªå©ªåŒºé—´)"
    }
    
    try:
        # åˆ›å»ºåˆ†æå¸ˆå®ä¾‹ï¼ˆéœ€è¦è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ï¼‰
        analyst = create_analyst()
        
        # æ‰§è¡Œåˆ†æ
        result = analyst.analyze_market("ETHUSDT", test_context)
        
        # æ‰“å°ç»“æœ
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†æç»“æœ")
        print("="*60)
        print(f"äº¤æ˜“å¯¹: {result.symbol}")
        print(f"é¢„æµ‹æ–¹å‘: {result.prediction}")
        print(f"ç½®ä¿¡åº¦: {result.confidence}%")
        print(f"é£é™©ç­‰çº§: {result.risk_level}")
        print(f"\nğŸ“ åˆ†ææ‘˜è¦:\n{result.summary}")
        print(f"\nâš ï¸ é£é™©è­¦å‘Š:")
        for warning in result.risk_warning:
            print(f"  â€¢ {warning}")
            
    except ValueError as e:
        print(f"é…ç½®é”™è¯¯: {e}")
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
